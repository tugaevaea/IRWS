{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Space Model\n",
    "#### TF-IDF dictionary (checked with Elina's solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import copy\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MED-118</td>\n",
       "      <td>alkylphenols human milk relations dietary habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MED-329</td>\n",
       "      <td>phosphate vascular toxin pubmed ncbi abstract ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MED-330</td>\n",
       "      <td>dietary phosphorus acutely impairs endothelial...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MED-332</td>\n",
       "      <td>public health impact dietary phosphorus excess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MED-334</td>\n",
       "      <td>differences total vitro digestible phosphorus ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                               TEXT\n",
       "0  MED-118  alkylphenols human milk relations dietary habi...\n",
       "1  MED-329  phosphate vascular toxin pubmed ncbi abstract ...\n",
       "2  MED-330  dietary phosphorus acutely impairs endothelial...\n",
       "3  MED-332  public health impact dietary phosphorus excess...\n",
       "4  MED-334  differences total vitro digestible phosphorus ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enter your path of the corpus\n",
    "path = 'C:/Users/48668/Desktop/IR/project/nfcorpus/'\n",
    "\n",
    "# load corpus as preprocessed set of documents\n",
    "corpus = pd.read_csv(path + 'dev.docs', sep='\\t', names=['ID', 'TEXT'])\n",
    "\n",
    "# preview first rows\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008547008547008548"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create token list out of document\n",
    "def tokenize(string):\n",
    "    return string.split()\n",
    "\n",
    "# apply term frequencies for each a single string (document)\n",
    "def tf(string): \n",
    "    # create bag of words from the string\n",
    "    bow = tokenize(string)\n",
    "    \n",
    "    tf_dict = {}\n",
    "    for word in bow:\n",
    "        if word in tf_dict:\n",
    "            tf_dict[word] += 1\n",
    "        else:\n",
    "            tf_dict[word] = 1\n",
    "            \n",
    "    for word in tf_dict:\n",
    "        tf_dict[word] = tf_dict[word]/len(bow)### ??\n",
    "    \n",
    "    return tf_dict\n",
    "\n",
    "\n",
    "# We then call our function on every doc and store all these tf dictionaries. \n",
    "tf_dict = {}\n",
    "for index, row in corpus.iterrows():\n",
    "    doc_dict = tf(row['TEXT'])\n",
    "    tf_dict[index] = doc_dict\n",
    "\n",
    "# test if tfDict was created correctly\n",
    "tf_dict[0][\"alkylphenols\"]\n",
    "\n",
    "# alkylphenols for doc 0 : 0.008547008547008548"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3193\n"
     ]
    }
   ],
   "source": [
    "# total number of documents in corpus\n",
    "no_of_docs = len(corpus.index)\n",
    "print(no_of_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# term - key, number of docs term occured in\n",
    "def count_occurances():\n",
    "    count_dict = {}\n",
    "    for key in tf_dict:\n",
    "        for key in tf_dict[key]:\n",
    "            if key in count_dict:\n",
    "                count_dict[key] += 1\n",
    "            else:\n",
    "                count_dict[key] = 1\n",
    "    return count_dict\n",
    "\n",
    "# test if count_occurances works\n",
    "count_oc = count_occurances()\n",
    "count_oc[\"alkylphenols\"] # checked with Elina, good\n",
    "\n",
    "# number of alkylphenols occurence in entire corpus = 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "467016\n"
     ]
    }
   ],
   "source": [
    "# number of all not unique words to check total number of words (just fyi)\n",
    "total = 0\n",
    "for index, row in corpus.iterrows():\n",
    "    total += len(tokenize(row['TEXT']))\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.122806043659469"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# having total number of documents and number of occurances of each word in entire corpus we can calculate \n",
    "# idf for each term as log(total # of documents / # of documents with term in it)\n",
    "\n",
    "# idf is calculated per each term, thus we create dictionary with term as a key and idf as a value\n",
    "def idf():\n",
    "    \n",
    "    idf_dict = {}\n",
    "    for key in count_oc:\n",
    "        idf_dict[key] = math.log(no_of_docs/count_oc[key])\n",
    "    return idf_dict\n",
    "\n",
    "idf = idf()\n",
    "\n",
    "# test if idf function works\n",
    "idf[\"alkylphenols\"]\n",
    "\n",
    "# alkylphenols idf = 6.122806043659469"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result from def:\n",
      "0.05233167558683307\n",
      "Manual result:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.05233167558683307"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cosntructing the final tf-idf dictionary; tf-idf is calculated as tf-idf(t, d) = tf(t, d) * idf(t)\n",
    "# so for each key in tf dict we have to miltiply it with corresponsinf idf value\n",
    "\n",
    "def tf_idf():\n",
    "    d = copy.deepcopy(tf_dict)\n",
    "    for doc, value in d.items():\n",
    "        for word, value in d[doc].items():\n",
    "            d[doc][word] = value * idf[word]\n",
    "    return d\n",
    "\n",
    "# test if tf_idf works\n",
    "a = tf_idf()\n",
    "print('Result from def:')\n",
    "print(a[0][\"alkylphenols\"])\n",
    "\n",
    "# excpected result for (term, doc) --> (alkylphenols, 0) =  0.008547008547008548 * 6.122806043659469 = 0.05\n",
    "print('Manual result:')\n",
    "idf[\"alkylphenols\"] * tf_dict[0][\"alkylphenols\"]\n",
    "\n",
    "# it works :) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coparing TF-IDF vectors (cosine similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alkylphenols</th>\n",
       "      <th>human</th>\n",
       "      <th>milk</th>\n",
       "      <th>relations</th>\n",
       "      <th>dietary</th>\n",
       "      <th>habits</th>\n",
       "      <th>central</th>\n",
       "      <th>taiwan</th>\n",
       "      <th>pubmed</th>\n",
       "      <th>ncbi</th>\n",
       "      <th>...</th>\n",
       "      <th>tuscany</th>\n",
       "      <th>studies-depression</th>\n",
       "      <th>suicides</th>\n",
       "      <th>eurosave</th>\n",
       "      <th>self-inflicted</th>\n",
       "      <th>eurostat</th>\n",
       "      <th>upward</th>\n",
       "      <th>suicide-recording</th>\n",
       "      <th>scarcity</th>\n",
       "      <th>trim-and-fill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.052332</td>\n",
       "      <td>0.041372</td>\n",
       "      <td>0.079999</td>\n",
       "      <td>0.046407</td>\n",
       "      <td>0.021178</td>\n",
       "      <td>0.060818</td>\n",
       "      <td>0.029952</td>\n",
       "      <td>0.047041</td>\n",
       "      <td>0.002278</td>\n",
       "      <td>0.002334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001777</td>\n",
       "      <td>0.001820</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022663</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001625</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001549</td>\n",
       "      <td>0.001588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007245</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001559</td>\n",
       "      <td>0.001597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002082</td>\n",
       "      <td>0.002133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001945</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016298</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002692</td>\n",
       "      <td>0.002758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 26951 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   alkylphenols     human      milk  relations   dietary    habits   central  \\\n",
       "0      0.052332  0.041372  0.079999   0.046407  0.021178  0.060818  0.029952   \n",
       "1      0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  0.000000   \n",
       "2      0.000000  0.000000  0.000000   0.000000  0.028372  0.000000  0.000000   \n",
       "3      0.000000  0.000000  0.000000   0.000000  0.022663  0.000000  0.000000   \n",
       "4      0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  0.000000   \n",
       "5      0.000000  0.000000  0.109472   0.000000  0.007245  0.000000  0.000000   \n",
       "6      0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  0.000000   \n",
       "7      0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  0.000000   \n",
       "8      0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  0.000000   \n",
       "9      0.000000  0.016298  0.000000   0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "     taiwan    pubmed      ncbi  ...  tuscany  studies-depression  suicides  \\\n",
       "0  0.047041  0.002278  0.002334  ...      0.0                 0.0       0.0   \n",
       "1  0.000000  0.001777  0.001820  ...      0.0                 0.0       0.0   \n",
       "2  0.000000  0.000000  0.000000  ...      0.0                 0.0       0.0   \n",
       "3  0.000000  0.001625  0.001665  ...      0.0                 0.0       0.0   \n",
       "4  0.000000  0.001549  0.001588  ...      0.0                 0.0       0.0   \n",
       "5  0.000000  0.001559  0.001597  ...      0.0                 0.0       0.0   \n",
       "6  0.000000  0.000000  0.000000  ...      0.0                 0.0       0.0   \n",
       "7  0.000000  0.002082  0.002133  ...      0.0                 0.0       0.0   \n",
       "8  0.000000  0.001945  0.001993  ...      0.0                 0.0       0.0   \n",
       "9  0.000000  0.002692  0.002758  ...      0.0                 0.0       0.0   \n",
       "\n",
       "   eurosave  self-inflicted  eurostat  upward  suicide-recording  scarcity  \\\n",
       "0       0.0             0.0       0.0     0.0                0.0       0.0   \n",
       "1       0.0             0.0       0.0     0.0                0.0       0.0   \n",
       "2       0.0             0.0       0.0     0.0                0.0       0.0   \n",
       "3       0.0             0.0       0.0     0.0                0.0       0.0   \n",
       "4       0.0             0.0       0.0     0.0                0.0       0.0   \n",
       "5       0.0             0.0       0.0     0.0                0.0       0.0   \n",
       "6       0.0             0.0       0.0     0.0                0.0       0.0   \n",
       "7       0.0             0.0       0.0     0.0                0.0       0.0   \n",
       "8       0.0             0.0       0.0     0.0                0.0       0.0   \n",
       "9       0.0             0.0       0.0     0.0                0.0       0.0   \n",
       "\n",
       "   trim-and-fill  \n",
       "0            0.0  \n",
       "1            0.0  \n",
       "2            0.0  \n",
       "3            0.0  \n",
       "4            0.0  \n",
       "5            0.0  \n",
       "6            0.0  \n",
       "7            0.0  \n",
       "8            0.0  \n",
       "9            0.0  \n",
       "\n",
       "[10 rows x 26951 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First we have to build TF-IDF matrix based on obtain dictionary. \n",
    "# Rows will correspond to docs in the corpus, while columns will represent unique words\n",
    "\n",
    "#              word1       ...          wordn\n",
    "#  doc1   tf_idf_value   ...      tf_idf_value\n",
    "#  ...    tf_idf_value   ...      tf_idf_value\n",
    "#  docn   tf_idf_value   ...      tf_idf_value\n",
    "#\n",
    "\n",
    "tf_idf_matrix = pd.DataFrame.from_dict(a, orient = 'index').fillna(0) # if word does not appear in doc we change NaN to\n",
    "tf_idf_matrix.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix has unique words\n"
     ]
    }
   ],
   "source": [
    "# cheching if my dataframe has actually set of unique words :)\n",
    "words = sorted(tf_idf_matrix.index)\n",
    "words \n",
    "\n",
    "wordsSet = set(words)\n",
    "if len(wordsSet) == len(words):\n",
    "    print(\"matrix has unique words\")\n",
    "else:\n",
    "    print(\"Error: matrix has not unique words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have to compare docs by computing cosine similarity between each vector (row) in dataframe\n",
    "# For that we need to obtain 1. vector magintude 2. dot product between two vectors\n",
    "\n",
    "def vector_magnitude(v):\n",
    "    return np.linalg.norm(v)\n",
    "\n",
    "def dot_product(v1, v2):\n",
    "    return np.dot(v1,v2)\n",
    "\n",
    "# Cosine similarity function:\n",
    "def cosine_similarity(v1, v2):\n",
    "    return dot_product(v1, v2)/ (vector_magnitude(v1) * vector_magnitude(v2))\n",
    "\n",
    "# Creating cosine similarity table (should be 3193 x 3193)\n",
    "# Here cosine_similarity() should be perfomed on entire dataframe.\n",
    "# ????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inverted index, tiered index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1262, 1263, 1270, 1271, 1277, 1280]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First let's try to implement champion list, means two-layer indexing\n",
    "# The result for each term should be {term: {0: [top_rank_list], 1: [lower_rank_list]}\n",
    "# For weighting we are going to use tf() function\n",
    "\n",
    "\n",
    "# Simple inverted index based on tf_dict {term: [list of docs], term1: [list of docs]}\n",
    "def inverted_index():\n",
    "    ii_dict = {}\n",
    "    for doc in tf_dict:\n",
    "        for term in tf_dict[doc]:            \n",
    "            if term in ii_dict:\n",
    "                ii_dict[term].append(doc)\n",
    "            else:           \n",
    "                ii_dict[term] = list()\n",
    "                ii_dict[term].append(doc)\n",
    "    return ii_dict\n",
    "\n",
    "ii_dict = inverted_index()\n",
    "ii_dict[\"alkylphenols\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.008547008547008548,\n",
       " 1262: 0.016260162601626018,\n",
       " 1263: 0.023255813953488372,\n",
       " 1270: 0.008547008547008548,\n",
       " 1271: 0.010309278350515464,\n",
       " 1277: 0.02127659574468085,\n",
       " 1280: 0.012121212121212121}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we have to modify inverted index by adding tf values for each doc \n",
    "# {term: {0: tf_value, 1: tf_value, ... , n: tf_value }}\n",
    "\n",
    "def tf_inverted_index():\n",
    "    tf_ii_dict = {}\n",
    "    for doc in tf_dict:\n",
    "        for term in tf_dict[doc]:\n",
    "            if term not in tf_ii_dict:\n",
    "                inner_dict = {}\n",
    "                tf_ii_dict[term] = inner_dict\n",
    "                inner_dict[doc] = tf_dict[doc][term]\n",
    "            else:\n",
    "                tf_ii_dict[term][doc] = tf_dict[doc][term]\n",
    "    return tf_ii_dict\n",
    "\n",
    "tf_ii_dict = tf_inverted_index()\n",
    "tf_ii_dict[\"alkylphenols\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sort function\n",
      "{1263: 0.023255813953488372, 1277: 0.02127659574468085, 1262: 0.016260162601626018, 1280: 0.012121212121212121, 1271: 0.010309278350515464, 0: 0.008547008547008548, 1270: 0.008547008547008548}\n",
      "\n",
      "Test splitting dict into chunks\n",
      "[{1263: 0.023255813953488372}, {1277: 0.02127659574468085}, {1262: 0.016260162601626018}, {1280: 0.012121212121212121}, {1271: 0.010309278350515464}, {0: 0.008547008547008548}, {1270: 0.008547008547008548}, {}]\n",
      "Test if chunks work on entire dictionary\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{1263: 0.023255813953488372,\n",
       "  1280: 0.012121212121212121,\n",
       "  1270: 0.008547008547008548},\n",
       " {1277: 0.02127659574468085, 1271: 0.010309278350515464},\n",
       " {1262: 0.016260162601626018, 0: 0.008547008547008548}]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next, we are modifying tf_ii_dict in order to obtain 2 tieres according to treshholds tr\n",
    "\n",
    "# 2. Calculate the length\n",
    "# 3. First 20% will be simply first (n = 20% * lenght) rows from the sorted list\n",
    "\n",
    "# 4. Once the dict is sorted, we will expand implementation of champion list into generic tiered index with k tieres\n",
    "\n",
    "# 1. Sort the values in dict in the descending order \n",
    "def sort_dict(tf_ii_dict):\n",
    "    for doc in tf_ii_dict:\n",
    "         tf_ii_dict[doc] = {k: v for k, v in sorted(test_dict.items(), key=lambda item: item[1], reverse=True)} #explain\n",
    "    return tf_ii_dict\n",
    "\n",
    "tf_ii_dict_sorted = sort_dict(tf_ii_dict)\n",
    "print(\"Test sort function\")\n",
    "print(tf_ii_dict_sorted[\"alkylphenols\"])\n",
    "\n",
    "# 2. Set top N values; for N = 3 --> list is broken down into 3 tires of the approximately(!)same length;\n",
    "\n",
    "# what kind of data structure we want for tires? \n",
    "# {word: tire1: [doc, doc, .., docn], tire2: [doc, doco, .., docn]}\n",
    "\n",
    "test = tf_ii_dict_sorted[\"alkylphenols\"]\n",
    "\n",
    "import itertools\n",
    "def split_dict(x, chunks):      \n",
    "    i = itertools.cycle(range(chunks))       \n",
    "    split = [dict() for _ in range(chunks)]\n",
    "    for k, v in x.items():\n",
    "        split[next(i)][k] = v\n",
    "    return split\n",
    "\n",
    "# Apply function to the whole dict\n",
    "\n",
    "def tiered_index(dictionary, chunks):\n",
    "    for doc in dictionary:\n",
    "          dictionary[doc] = split_dict(dictionary[doc],chunks)\n",
    "    return dictionary\n",
    "\n",
    "# Test what happens if number of chunks is bigger than dict length\n",
    "print(\"\\nTest splitting dict into chunks\")\n",
    "print(split_dict(test,8))\n",
    "# empty chunks are created, it would be good to remove them later on\n",
    "\n",
    "# Test tiered function\n",
    "print(\"Test if chunks work on entire dictionary\")\n",
    "tiered_index = tiered_index(tf_ii_dict_sorted, 3)\n",
    "tiered_index[\"alkylphenols\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
