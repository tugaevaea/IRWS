{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import copy\n",
    "import numpy as np \n",
    "import itertools\n",
    "import more_itertools as mit\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer \n",
    "import string\n",
    "import re\n",
    "\n",
    "from IPython import get_ipython\n",
    "\n",
    "get_ipython().magic('run -i \"1_preprocessing_corpus_queries.ipynb\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Term frequency\n",
    "def tf(corpus):\n",
    "    \n",
    "    def tokenize(string):\n",
    "        return string.split()\n",
    "    \n",
    "    def tf_string(string): \n",
    "        # create bag of words from the string\n",
    "        bow = tokenize(string)\n",
    "    \n",
    "        tf_dict = {}\n",
    "        for word in bow:\n",
    "            if word in tf_dict:\n",
    "                tf_dict[word] += 1\n",
    "            else:\n",
    "                tf_dict[word] = 1\n",
    "            \n",
    "        for word in tf_dict:\n",
    "            tf_dict[word] = tf_dict[word]/len(bow)### ??\n",
    "    \n",
    "        return tf_dict\n",
    "    \n",
    "    # call our function on every doc and store all these tf dictionaries. \n",
    "    tf_dict = {}\n",
    "    for index, row in corpus.iterrows():\n",
    "        doc_dict = tf_string(row[\"TEXT\"])\n",
    "        tf_dict[index] = doc_dict\n",
    "            \n",
    "    return tf_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inveresed document frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inversed document frequency\n",
    "def idf(corpus):\n",
    "    \n",
    "    tf_dict = tf(corpus)\n",
    "    \n",
    "    # nomber of documents in corpus\n",
    "    no_of_docs = len(corpus.index)\n",
    "    \n",
    "    # term - key, number of docs term occured in\n",
    "    def count_occurances(tf_dict):\n",
    "        count_dict = {}\n",
    "        for key in tf_dict:\n",
    "            for key in tf_dict[key]:\n",
    "                if key in count_dict:\n",
    "                    count_dict[key] += 1\n",
    "                else:\n",
    "                    count_dict[key] = 1\n",
    "        return count_dict\n",
    "\n",
    "    idf_dict = {}\n",
    "    \n",
    "    count_dict = count_occurances(tf_dict)\n",
    "    \n",
    "    for key in count_dict:\n",
    "        idf_dict[key] = math.log(no_of_docs/count_dict[key])\n",
    "    \n",
    "    return idf_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF\n",
    "def tf_idf(corpus):   \n",
    "    \n",
    "    tf_dict = tf(corpus)\n",
    "    idf_dict = idf(corpus)\n",
    "    \n",
    "    tf_idf_dict = copy.deepcopy(tf_dict)\n",
    "    for doc, value in tf_idf_dict.items():\n",
    "        for word, value in tf_idf_dict[doc].items():\n",
    "            tf_idf_dict[doc][word] = value * idf_dict[word]\n",
    "    return tf_idf_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine similarity\n",
    "def cosine_similarity(v1, v2):\n",
    "    \n",
    "    def vector_magnitude(v):\n",
    "        return np.linalg.norm(v)\n",
    "    \n",
    "    def dot_product(v1, v2):\n",
    "        return np.dot(v1,v2)\n",
    "    \n",
    "    return dot_product(v1, v2)/ (vector_magnitude(v1) * vector_magnitude(v2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF to matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tf_idf_dict to matrix\n",
    "def tf_idf_to_matrix(tf_idf_dict):\n",
    "    tf_idf_matrix = pd.DataFrame.from_dict(tf_idf_dict, \n",
    "                                           orient = 'index').fillna(0) # if word does not appear in doc we change NaN to\n",
    "    return tf_idf_matrix.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build tf-idf vectors for docs (once for the entire corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_doc_vectors(corpus):\n",
    "    tf_idf_dict = tf_idf(corpus)                              # tf-idf for docs\n",
    "    doc_vectors= tf_idf_to_matrix(tf_idf_dict)                # tf-idf dictionary for docs converted to matrix\n",
    "    return doc_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build tf-idf vector for one query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_q_vector(query, doc_vectors, idf_dict):\n",
    "    if type(query) == str:\n",
    "        tokenized_query = query.split()\n",
    "    else:\n",
    "        tokenized_query = query\n",
    "\n",
    "    df_query = doc_vectors[0:0]  # dataframe of tf-idf weights of a query\n",
    "    df_query = df_query.append(pd.Series(0, index=df_query.columns), ignore_index=True)\n",
    "    for token in tokenized_query:\n",
    "        for col in df_query.columns:\n",
    "            if token == col:\n",
    "                df_query[col][0] = df_query[col][0] + 1  # raw term frequency\n",
    "\n",
    "    df_query = df_query.replace(0, np.nan)\n",
    "\n",
    "    df_query = np.log(df_query) + 1  # log term freq(as in the slides)\n",
    "\n",
    "    df_query = df_query.fillna(0)\n",
    "\n",
    "    for col in df_query.columns:\n",
    "        df_query[col][0] = df_query[col][0] * idf_dict[col]\n",
    "\n",
    "    return df_query.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_retrieve(q_vector, doc_vectors, top_k, random_projections=False):\n",
    "    \"\"\"\n",
    "    Retrieve top relevant document for input query.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    doc_vectors:              tf-idf matrix of a corpus: build_doc_vectors() function\n",
    "    q_vector:                 tf-idf vector for queries\n",
    "    top_k:                    number of most relevant documents to be output\n",
    "    random_projections=False  if retrieval should be done with random projections\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    df.iloc[ids]     dataframe with IDs of predicted top_k most relevant documents with their content\n",
    "    \"\"\"\n",
    "    \n",
    "    df = corpus.copy()\n",
    "\n",
    "    sim = []                                                     # to store cosine similarities\n",
    "    sort_sim = []                                                # sorted cosine similarities\n",
    "    i = 0\n",
    "    for doc in doc_vectors.values:\n",
    "        #in case of random projections calculate dot product since our document and query vectors would be unit-normalized\n",
    "        if random_projections:\n",
    "            sim.append([i, np.dot(q_vector, doc)])\n",
    "        else:\n",
    "            sim.append([i, cosine_similarity(q_vector, doc)])\n",
    "        i += 1\n",
    "    sort_sim = sorted(sim, key=lambda cos: cos[1], reverse=True)\n",
    "    ids = []\n",
    "\n",
    "    for j in range(top_k):\n",
    "        ids.append(sort_sim[j][0])\n",
    "\n",
    "    return df.iloc[ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST (find 5 most relevant documents for first query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>MED-2423</td>\n",
       "      <td>dietari pattern breast cancer risk women pubm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>MED-2195</td>\n",
       "      <td>influenc deep fri veget oil acrylamid format s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>MED-3498</td>\n",
       "      <td>dietari acrylamid exposur french popul result ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>MED-2422</td>\n",
       "      <td>statist regress model estim acrylamid concentr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>MED-2418</td>\n",
       "      <td>consumpt deep-fri food risk prostat cancera b ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                                               TEXT\n",
       "1142  MED-2423  dietari pattern breast cancer risk women pubm ...\n",
       "956   MED-2195  influenc deep fri veget oil acrylamid format s...\n",
       "1794  MED-3498  dietari acrylamid exposur french popul result ...\n",
       "1141  MED-2422  statist regress model estim acrylamid concentr...\n",
       "1138  MED-2418  consumpt deep-fri food risk prostat cancera b ..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load corpus \n",
    "corpus = preprocess_corpus(pd.read_csv('nfcorpus/dev.docs', sep='\\t', names=['ID', 'TEXT']))\n",
    "\n",
    "# load queries\n",
    "queries = preprocess_queries(corpus, pd.read_csv('nfcorpus/dev.all.queries', sep='\\t', names=['ID', 'TEXT']))\n",
    "\n",
    "# call needed arguments\n",
    "doc_vectors = build_doc_vectors(corpus)\n",
    "idf_dict = idf(corpus)\n",
    "q_vector = build_q_vector(queries['TEXT'][0], doc_vectors, idf_dict)\n",
    "\n",
    "# call retrieve\n",
    "test = basic_retrieve(q_vector = q_vector,\n",
    "                      doc_vectors = doc_vectors, \n",
    "                      top_k = 5)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evalutaion for queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation for query titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
