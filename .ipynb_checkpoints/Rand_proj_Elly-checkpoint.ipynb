{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import faiss                   # make faiss available\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import scipy.sparse as sp\n",
    "import collections\n",
    "import math\n",
    "import copy\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic 4: Efficient Vector Space Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and vectorize using TfidfVectorizer\n",
    "https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction\n",
    "\n",
    "TF-IDF weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MED-118</td>\n",
       "      <td>alkylphenols human milk relations dietary habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MED-329</td>\n",
       "      <td>phosphate vascular toxin pubmed ncbi abstract ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MED-330</td>\n",
       "      <td>dietary phosphorus acutely impairs endothelial...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MED-332</td>\n",
       "      <td>public health impact dietary phosphorus excess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MED-334</td>\n",
       "      <td>differences total vitro digestible phosphorus ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MED-335</td>\n",
       "      <td>differences total vitro digestible phosphorus ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MED-398</td>\n",
       "      <td>grapefruit wine glass metabolic cardiovascular...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MED-557</td>\n",
       "      <td>dysmenorrhea pubmed ncbi abstract dysmenorrhea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MED-666</td>\n",
       "      <td>role surgery treatment mastalgia pubmed ncbi a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MED-691</td>\n",
       "      <td>ginger prevention nausea vomiting review pubme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MED-692</td>\n",
       "      <td>effectiveness safety ginger pregnancy-induced ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MED-706</td>\n",
       "      <td>aqueous extract hibiscus sabdariffa calices mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MED-707</td>\n",
       "      <td>uricosuric effect roselle hibiscus sabdariffa ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MED-708</td>\n",
       "      <td>inhibitory effect marinades hibiscus extract f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MED-709</td>\n",
       "      <td>testicular effects sub-chronic administration ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MED-711</td>\n",
       "      <td>effects hibiscus sabdariffa extract powder pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MED-712</td>\n",
       "      <td>chemopreventive properties molecular mechanism...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MED-713</td>\n",
       "      <td>effects water extract hibiscus sabdariffa linn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MED-714</td>\n",
       "      <td>prevention vitamin deficiency knowledge gaps r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MED-716</td>\n",
       "      <td>vitamin d-lightful solution health abstract ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MED-717</td>\n",
       "      <td>fructose intake current levels united states g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MED-718</td>\n",
       "      <td>relation passage gas abdominal bloating coloni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MED-719</td>\n",
       "      <td>flatulence--causes relation diet remedies pubm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>MED-720</td>\n",
       "      <td>effect oral alpha-galactosidase intestinal gas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>MED-721</td>\n",
       "      <td>bismuth therapy gastrointestinal diseases pubm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>MED-722</td>\n",
       "      <td>understanding excessive intestinal gas pubmed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>MED-723</td>\n",
       "      <td>effectiveness devices purported reduce flatus ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>MED-724</td>\n",
       "      <td>flatulence--causes relation diet remedies pubm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>MED-726</td>\n",
       "      <td>association alzheimer disease pathology abnorm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>MED-727</td>\n",
       "      <td>illuminating black box description num patient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3163</th>\n",
       "      <td>MED-5325</td>\n",
       "      <td>vegetarian diets blood pressure white subjects...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3164</th>\n",
       "      <td>MED-5326</td>\n",
       "      <td>red meat colon cancer vegetarians make meat sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3165</th>\n",
       "      <td>MED-5327</td>\n",
       "      <td>association dietary patterns mental health ear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3166</th>\n",
       "      <td>MED-5328</td>\n",
       "      <td>vegetarian diets incidence diabetes adventist ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3167</th>\n",
       "      <td>MED-5329</td>\n",
       "      <td>rapid reduction serum cholesterol blood pressu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3168</th>\n",
       "      <td>MED-5330</td>\n",
       "      <td>effect single high-fat meal endothelial functi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3169</th>\n",
       "      <td>MED-5331</td>\n",
       "      <td>influencing public nutrition non-communicable ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3170</th>\n",
       "      <td>MED-5332</td>\n",
       "      <td>quantification butyryl coa:acetate coa-transfe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3171</th>\n",
       "      <td>MED-5333</td>\n",
       "      <td>vegetarian diet affects genes oxidative metabo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3172</th>\n",
       "      <td>MED-5334</td>\n",
       "      <td>protein-source tryptophan efficacious treatmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3173</th>\n",
       "      <td>MED-5335</td>\n",
       "      <td>vegan diet reduce risk parkinson's disease pub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3174</th>\n",
       "      <td>MED-5337</td>\n",
       "      <td>intensive lifestyle affect progression prostat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3175</th>\n",
       "      <td>MED-5338</td>\n",
       "      <td>original articles vegetarian compared meat die...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3176</th>\n",
       "      <td>MED-5339</td>\n",
       "      <td>escherichia coli urinary tract infection zoono...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3177</th>\n",
       "      <td>MED-5340</td>\n",
       "      <td>renal function parameters thai vegans compared...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3178</th>\n",
       "      <td>MED-5341</td>\n",
       "      <td>effects low-fat high-fiber diet exercise progr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3179</th>\n",
       "      <td>MED-5342</td>\n",
       "      <td>vegetarian diets healthy mood states cross-sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3180</th>\n",
       "      <td>MED-5345</td>\n",
       "      <td>years err human learned pubmed ncbi abstract y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3181</th>\n",
       "      <td>MED-5360</td>\n",
       "      <td>fruit vegetable antioxidant intakes lower olde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3182</th>\n",
       "      <td>MED-5361</td>\n",
       "      <td>double-blind randomized controlled clinical tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3183</th>\n",
       "      <td>MED-5362</td>\n",
       "      <td>systematic review meta-analysis dietary patter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3184</th>\n",
       "      <td>MED-5363</td>\n",
       "      <td>dietary patterns depressive symptoms japanese ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3185</th>\n",
       "      <td>MED-5364</td>\n",
       "      <td>long chain num fatty acids intake fish consump...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3186</th>\n",
       "      <td>MED-5365</td>\n",
       "      <td>antioxidants antidepressants fact fiction pubm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3187</th>\n",
       "      <td>MED-5366</td>\n",
       "      <td>association mediterranean dietary pattern inci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3188</th>\n",
       "      <td>MED-5367</td>\n",
       "      <td>relationship plasma carotenoids depressive sym...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3189</th>\n",
       "      <td>MED-5368</td>\n",
       "      <td>suicide mortality relation dietary intake num ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3190</th>\n",
       "      <td>MED-5369</td>\n",
       "      <td>suicide mortality european union pubmed ncbi a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3191</th>\n",
       "      <td>MED-5370</td>\n",
       "      <td>long chain omega num fatty acids intake fish c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3192</th>\n",
       "      <td>MED-5371</td>\n",
       "      <td>omega num fatty acids treatment depression sys...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3193 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                                               TEXT\n",
       "0      MED-118  alkylphenols human milk relations dietary habi...\n",
       "1      MED-329  phosphate vascular toxin pubmed ncbi abstract ...\n",
       "2      MED-330  dietary phosphorus acutely impairs endothelial...\n",
       "3      MED-332  public health impact dietary phosphorus excess...\n",
       "4      MED-334  differences total vitro digestible phosphorus ...\n",
       "5      MED-335  differences total vitro digestible phosphorus ...\n",
       "6      MED-398  grapefruit wine glass metabolic cardiovascular...\n",
       "7      MED-557  dysmenorrhea pubmed ncbi abstract dysmenorrhea...\n",
       "8      MED-666  role surgery treatment mastalgia pubmed ncbi a...\n",
       "9      MED-691  ginger prevention nausea vomiting review pubme...\n",
       "10     MED-692  effectiveness safety ginger pregnancy-induced ...\n",
       "11     MED-706  aqueous extract hibiscus sabdariffa calices mo...\n",
       "12     MED-707  uricosuric effect roselle hibiscus sabdariffa ...\n",
       "13     MED-708  inhibitory effect marinades hibiscus extract f...\n",
       "14     MED-709  testicular effects sub-chronic administration ...\n",
       "15     MED-711  effects hibiscus sabdariffa extract powder pre...\n",
       "16     MED-712  chemopreventive properties molecular mechanism...\n",
       "17     MED-713  effects water extract hibiscus sabdariffa linn...\n",
       "18     MED-714  prevention vitamin deficiency knowledge gaps r...\n",
       "19     MED-716  vitamin d-lightful solution health abstract ev...\n",
       "20     MED-717  fructose intake current levels united states g...\n",
       "21     MED-718  relation passage gas abdominal bloating coloni...\n",
       "22     MED-719  flatulence--causes relation diet remedies pubm...\n",
       "23     MED-720  effect oral alpha-galactosidase intestinal gas...\n",
       "24     MED-721  bismuth therapy gastrointestinal diseases pubm...\n",
       "25     MED-722  understanding excessive intestinal gas pubmed ...\n",
       "26     MED-723  effectiveness devices purported reduce flatus ...\n",
       "27     MED-724  flatulence--causes relation diet remedies pubm...\n",
       "28     MED-726  association alzheimer disease pathology abnorm...\n",
       "29     MED-727  illuminating black box description num patient...\n",
       "...        ...                                                ...\n",
       "3163  MED-5325  vegetarian diets blood pressure white subjects...\n",
       "3164  MED-5326  red meat colon cancer vegetarians make meat sa...\n",
       "3165  MED-5327  association dietary patterns mental health ear...\n",
       "3166  MED-5328  vegetarian diets incidence diabetes adventist ...\n",
       "3167  MED-5329  rapid reduction serum cholesterol blood pressu...\n",
       "3168  MED-5330  effect single high-fat meal endothelial functi...\n",
       "3169  MED-5331  influencing public nutrition non-communicable ...\n",
       "3170  MED-5332  quantification butyryl coa:acetate coa-transfe...\n",
       "3171  MED-5333  vegetarian diet affects genes oxidative metabo...\n",
       "3172  MED-5334  protein-source tryptophan efficacious treatmen...\n",
       "3173  MED-5335  vegan diet reduce risk parkinson's disease pub...\n",
       "3174  MED-5337  intensive lifestyle affect progression prostat...\n",
       "3175  MED-5338  original articles vegetarian compared meat die...\n",
       "3176  MED-5339  escherichia coli urinary tract infection zoono...\n",
       "3177  MED-5340  renal function parameters thai vegans compared...\n",
       "3178  MED-5341  effects low-fat high-fiber diet exercise progr...\n",
       "3179  MED-5342  vegetarian diets healthy mood states cross-sec...\n",
       "3180  MED-5345  years err human learned pubmed ncbi abstract y...\n",
       "3181  MED-5360  fruit vegetable antioxidant intakes lower olde...\n",
       "3182  MED-5361  double-blind randomized controlled clinical tr...\n",
       "3183  MED-5362  systematic review meta-analysis dietary patter...\n",
       "3184  MED-5363  dietary patterns depressive symptoms japanese ...\n",
       "3185  MED-5364  long chain num fatty acids intake fish consump...\n",
       "3186  MED-5365  antioxidants antidepressants fact fiction pubm...\n",
       "3187  MED-5366  association mediterranean dietary pattern inci...\n",
       "3188  MED-5367  relationship plasma carotenoids depressive sym...\n",
       "3189  MED-5368  suicide mortality relation dietary intake num ...\n",
       "3190  MED-5369  suicide mortality european union pubmed ncbi a...\n",
       "3191  MED-5370  long chain omega num fatty acids intake fish c...\n",
       "3192  MED-5371  omega num fatty acids treatment depression sys...\n",
       "\n",
       "[3193 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.read_csv('nfcorpus/dev.docs', sep='\\t', names=['ID', 'TEXT'])\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create token list out of document\n",
    "def tokenize(string):\n",
    "    return string.split()\n",
    "\n",
    "# apply term frequencies for each a single string (document)\n",
    "def tf(string): \n",
    "    # create bag of words from the string\n",
    "    bow = tokenize(string)\n",
    "    \n",
    "    tf_dict = {}\n",
    "    for word in bow:\n",
    "        if word in tf_dict:\n",
    "            tf_dict[word] += 1\n",
    "        else:\n",
    "            tf_dict[word] = 1\n",
    "            \n",
    "    for word in tf_dict:\n",
    "        tf_dict[word] = tf_dict[word] / len(bow)\n",
    "    \n",
    "    return tf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008547008547008548"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# We then call our function on every doc and store all these tf dictionaries. \n",
    "tf_dict = {}\n",
    "for index, row in corpus.iterrows():\n",
    "    doc_dict = tf(row['TEXT'])\n",
    "    tf_dict[index] = doc_dict\n",
    "\n",
    "# test if tfDict was created correctly\n",
    "tf_dict[0][\"alkylphenols\"]\n",
    "# alkylphenols for doc 0 : 0.008547008547008548"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3193\n"
     ]
    }
   ],
   "source": [
    "# total number of documents in corpus\n",
    "no_of_docs = len(corpus.index)\n",
    "print(no_of_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# term - key, number of docs term occured in\n",
    "def count_occurances():\n",
    "    count_dict = {}\n",
    "    for key in tf_dict:\n",
    "        for key in tf_dict[key]:\n",
    "            if key in count_dict:\n",
    "                count_dict[key] += 1\n",
    "            else:\n",
    "                count_dict[key] = 1\n",
    "    return count_dict\n",
    "\n",
    "# test if count_occurances works\n",
    "count_oc = count_occurances()\n",
    "count_oc[\"alkylphenols\"] # checked with Elina, good\n",
    "\n",
    "# number of alkylphenols occurence in entire corpus = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.122806043659469"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# having total number of documents and number of occurances of each word in entire corpus we can calculate \n",
    "# idf for each term as log(total # of documents / # of documents with term in it)\n",
    "\n",
    "# idf is calculated per each term, thus we create dictionary with term as a key and idf as a value\n",
    "def idf():\n",
    "    \n",
    "    idf_dict = {}\n",
    "    for key in count_oc:\n",
    "        idf_dict[key] = math.log(no_of_docs/count_oc[key])\n",
    "    return idf_dict\n",
    "\n",
    "idf = idf()\n",
    "\n",
    "# test if idf function works\n",
    "idf[\"alkylphenols\"]\n",
    "\n",
    "# alkylphenols idf = 6.122806043659469"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result from def:\n",
      "0.05233167558683307\n",
      "Manual result:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.05233167558683307"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cosntructing the final tf-idf dictionary; tf-idf is calculated as tf-idf(t, d) = tf(t, d) * idf(t)\n",
    "# so for each key in tf dict we have to miltiply it with corresponsinf idf value\n",
    "\n",
    "def tf_idf():\n",
    "    d = copy.deepcopy(tf_dict)\n",
    "    for doc, value in d.items():\n",
    "        for word, value in d[doc].items():\n",
    "            d[doc][word] = value * idf[word]\n",
    "    return d\n",
    "\n",
    "# test if tf_idf works\n",
    "a = tf_idf()\n",
    "print('Result from def:')\n",
    "print(a[0][\"alkylphenols\"])\n",
    "\n",
    "# excpected result for (term, doc) --> (alkylphenols, 0) =  0.008547008547008548 * 6.122806043659469 = 0.05\n",
    "print('Manual result:')\n",
    "idf[\"alkylphenols\"] * tf_dict[0][\"alkylphenols\"]\n",
    "\n",
    "# it works :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alkylphenols</th>\n",
       "      <th>human</th>\n",
       "      <th>milk</th>\n",
       "      <th>relations</th>\n",
       "      <th>dietary</th>\n",
       "      <th>habits</th>\n",
       "      <th>central</th>\n",
       "      <th>taiwan</th>\n",
       "      <th>pubmed</th>\n",
       "      <th>ncbi</th>\n",
       "      <th>...</th>\n",
       "      <th>tuscany</th>\n",
       "      <th>studies-depression</th>\n",
       "      <th>suicides</th>\n",
       "      <th>eurosave</th>\n",
       "      <th>self-inflicted</th>\n",
       "      <th>eurostat</th>\n",
       "      <th>upward</th>\n",
       "      <th>suicide-recording</th>\n",
       "      <th>scarcity</th>\n",
       "      <th>trim-and-fill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.052332</td>\n",
       "      <td>0.041372</td>\n",
       "      <td>0.079999</td>\n",
       "      <td>0.046407</td>\n",
       "      <td>0.021178</td>\n",
       "      <td>0.060818</td>\n",
       "      <td>0.029952</td>\n",
       "      <td>0.047041</td>\n",
       "      <td>0.002278</td>\n",
       "      <td>0.002334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001777</td>\n",
       "      <td>0.001820</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022663</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001625</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001549</td>\n",
       "      <td>0.001588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26951 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   alkylphenols     human      milk  relations   dietary    habits   central  \\\n",
       "0      0.052332  0.041372  0.079999   0.046407  0.021178  0.060818  0.029952   \n",
       "1      0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  0.000000   \n",
       "2      0.000000  0.000000  0.000000   0.000000  0.028372  0.000000  0.000000   \n",
       "3      0.000000  0.000000  0.000000   0.000000  0.022663  0.000000  0.000000   \n",
       "4      0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "     taiwan    pubmed      ncbi  ...  tuscany  studies-depression  suicides  \\\n",
       "0  0.047041  0.002278  0.002334  ...      0.0                 0.0       0.0   \n",
       "1  0.000000  0.001777  0.001820  ...      0.0                 0.0       0.0   \n",
       "2  0.000000  0.000000  0.000000  ...      0.0                 0.0       0.0   \n",
       "3  0.000000  0.001625  0.001665  ...      0.0                 0.0       0.0   \n",
       "4  0.000000  0.001549  0.001588  ...      0.0                 0.0       0.0   \n",
       "\n",
       "   eurosave  self-inflicted  eurostat  upward  suicide-recording  scarcity  \\\n",
       "0       0.0             0.0       0.0     0.0                0.0       0.0   \n",
       "1       0.0             0.0       0.0     0.0                0.0       0.0   \n",
       "2       0.0             0.0       0.0     0.0                0.0       0.0   \n",
       "3       0.0             0.0       0.0     0.0                0.0       0.0   \n",
       "4       0.0             0.0       0.0     0.0                0.0       0.0   \n",
       "\n",
       "   trim-and-fill  \n",
       "0            0.0  \n",
       "1            0.0  \n",
       "2            0.0  \n",
       "3            0.0  \n",
       "4            0.0  \n",
       "\n",
       "[5 rows x 26951 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# First we have to build TF-IDF matrix based on obtain dictionary. \n",
    "# Rows will correspond to docs in the corpus, while columns will represent unique words\n",
    "\n",
    "#              word1       ...          wordn\n",
    "#  doc1   tf_idf_value   ...      tf_idf_value\n",
    "#  ...    tf_idf_value   ...      tf_idf_value\n",
    "#  docn   tf_idf_value   ...      tf_idf_value\n",
    "#\n",
    "\n",
    "tf_idf_matrix = pd.DataFrame.from_dict(a, orient = 'index').fillna(0) # if word does not appear in doc we change NaN to 0\n",
    "tf_idf_matrix = tf_idf_matrix.sort_index()\n",
    "tf_idf_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alkylphenols             0.052332\n",
      "human                    0.041372\n",
      "milk                     0.079999\n",
      "relations                0.046407\n",
      "dietary                  0.021178\n",
      "habits                   0.060818\n",
      "central                  0.029952\n",
      "taiwan                   0.047041\n",
      "pubmed                   0.002278\n",
      "ncbi                     0.002334\n",
      "abstract                 0.000056\n",
      "aims                     0.031299\n",
      "study                    0.006299\n",
      "determine                0.019019\n",
      "concentrations           0.034312\n",
      "num                      0.017474\n",
      "nonylphenol              0.050184\n",
      "np                       0.110415\n",
      "octylphenol              0.055208\n",
      "op                       0.193874\n",
      "samples                  0.019661\n",
      "examine                  0.023895\n",
      "related                  0.018125\n",
      "factors                  0.014389\n",
      "including                0.015695\n",
      "mothers                  0.084329\n",
      "demographics             0.045818\n",
      "women                    0.015158\n",
      "consumed                 0.041914\n",
      "median                   0.028045\n",
      "                           ...   \n",
      "mmrm                     0.000000\n",
      "symptomatology-self      0.000000\n",
      "qids-sr                  0.000000\n",
      "improvement-severity     0.000000\n",
      "cgi-s                    0.000000\n",
      "meta-analyzed            0.000000\n",
      "checkup                  0.000000\n",
      "ces-d                    0.000000\n",
      "women--the               0.000000\n",
      "jphc                     0.000000\n",
      "noradrenaline            0.000000\n",
      "co-adjuvant              0.000000\n",
      "navarra/university       0.000000\n",
      "fol                      0.000000\n",
      "mdp                      0.000000\n",
      "saturated-fatty-acids    0.000000\n",
      "whole-fat                0.000000\n",
      "physician-made           0.000000\n",
      "six-year                 0.000000\n",
      "inchianti                0.000000\n",
      "tuscany                  0.000000\n",
      "studies-depression       0.000000\n",
      "suicides                 0.000000\n",
      "eurosave                 0.000000\n",
      "self-inflicted           0.000000\n",
      "eurostat                 0.000000\n",
      "upward                   0.000000\n",
      "suicide-recording        0.000000\n",
      "scarcity                 0.000000\n",
      "trim-and-fill            0.000000\n",
      "Name: 0, Length: 26951, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9999999999999996"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we have to compare docs by computing cosine similarity between each vector (row) in dataframe\n",
    "# For that we need to obtain 1. vector magnitude 2. dot product between two vectors\n",
    "\n",
    "def vector_magnitude(v):\n",
    "    return np.linalg.norm(v)\n",
    "\n",
    "def dot_product(v1, v2):\n",
    "    return np.dot(v1,v2)\n",
    "\n",
    "# Creating cosine similarity table (should be 3193 x 3193)\n",
    "def cosine_similarity(v1, v2):\n",
    "    return dot_product(v1, v2)/ (vector_magnitude(v1) * vector_magnitude(v2))\n",
    "print(tf_idf_matrix.iloc[0])\n",
    "cosine_similarity(tf_idf_matrix.iloc[0],tf_idf_matrix.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Projections\n",
    "**Hashing algorithm:**\n",
    "<br>1.Choose a set of *$M$* random vectors ${r_1, r_2, ..., r_M}$ in the original high-dimensional vectors space (vector length $|V|$)\n",
    "<br>2.For each document TF-IDF vector d do:\n",
    " - Compute the inner (dot) product of doc and each random vector $r:θ(r, d) = \\sum_{i}^{|𝑉|}𝑟_𝑖∗𝑑_𝑖$\n",
    " - Hash each inner product: $h(d, r_k) = 1$ if $θ(r, d) > t$ (treshold), else 0\n",
    "\n",
    "3.Compute a new vector of hashes:\n",
    " - $d’ = [h(d, r_1), h(d, r_2), ..., h(d, r_M)]$\n",
    " - The number of selected random vectors, *$M$*, is the dimensionality of hashed vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a function for  creating a set of M random vectors with the dimension dim\n",
    "def get_random_vectors(dim,m):\n",
    "    return np.random.random_sample((m, dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension of the set of random vectors:  (100, 26951)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.06284314, 0.51746825, 0.9356375 , ..., 0.81412037, 0.24848416,\n",
       "       0.09751716])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test the get_random_vectors\n",
    "vocab_size = len(tf_idf_matrix.columns)\n",
    "np.random.seed(0)\n",
    "m = 100\n",
    "random_vectors = get_random_vectors(vocab_size, m)\n",
    "print('dimension of the set of random vectors: ', random_vectors.shape)\n",
    "random_vectors[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d - document vector\n",
    "# rnd_vec - set of random vectors\n",
    "# t - threshold\n",
    "def norm(vec):\n",
    "    return vec/vector_magnitude(vec)\n",
    "    \n",
    "    \n",
    "def compute_hash(docs, rnd_vec, t):\n",
    "    hashed_doc_vectors = []\n",
    "    #for each document in document collection\n",
    "    for doc in docs:\n",
    "        hashed_dot_product = []\n",
    "        inner_product = doc.dot(rnd_vec.transpose())\n",
    "        for i in inner_product:  \n",
    "            if i>t:\n",
    "                hashed_dot_product.append(1)\n",
    "            else:\n",
    "                hashed_dot_product.append(0)\n",
    "        hashed_doc_vectors.append(hashed_dot_product)\n",
    "    return np.array(hashed_doc_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.52935202 1.40158704 1.37560483 1.40460678 1.25290627 1.56556019\n",
      " 1.19668373 1.50428146 1.32872635 1.70703534 1.1779663  1.3402548\n",
      " 1.43852473 1.39830539 1.26146833 1.47158566 1.29046752 1.50346167\n",
      " 1.21262387 1.46803553 1.48094456 1.30494526 1.23609255 1.63103709\n",
      " 1.2354678  1.32023814 1.40655926 1.28845768 1.54915213 1.28072208\n",
      " 1.60531398 1.34482263 1.4346691  1.45906407 1.39824523 1.51955422\n",
      " 1.28433195 1.26968334 1.31652239 1.35567704 1.32194379 1.39671996\n",
      " 1.45932261 1.23691701 1.18106196 1.33183443 1.47699914 1.26385761\n",
      " 1.57970796 1.23144514 1.33786753 1.37532657 1.28572843 1.2927297\n",
      " 1.36897493 1.51295204 1.70902037 1.16520591 1.23202941 1.52018073\n",
      " 1.33785418 1.56110283 1.48080842 1.39851598 1.38365494 1.44223707\n",
      " 1.33886896 1.32950293 1.41556142 1.56642664 1.47891912 1.3567732\n",
      " 1.43461308 1.44973598 1.40005237 1.44120087 1.37411145 1.2967823\n",
      " 1.29051957 1.34881912 1.47508042 1.68026367 1.46225666 1.30655028\n",
      " 1.22878692 1.54757521 1.45004802 1.31474515 1.56693045 1.26252524\n",
      " 1.61837239 1.55539627 1.49840788 1.31154092 1.48819855 1.25317488\n",
      " 1.28487356 1.53601833 1.36141988 1.40635743]\n",
      "[1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "#test compute_hash\n",
    "doc_vectors = tf_idf_matrix.values\n",
    "inn = doc_vectors[0].dot(random_vectors.transpose())\n",
    "h = []\n",
    "for i in inn:\n",
    "    if i>1.2:\n",
    "        h.append(1)\n",
    "    else:\n",
    "        h.append(0)\n",
    "print(inn)\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_projections = compute_hash(doc_vectors, random_vectors, 1.2)\n",
    "random_projections[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use random projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>why deep fried foods may cause cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PLAIN-1007</td>\n",
       "      <td>ddt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PLAIN-101</td>\n",
       "      <td>how to treat multiple sclerosis with diet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PLAIN-1017</td>\n",
       "      <td>detoxification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PLAIN-1027</td>\n",
       "      <td>dietary guidelines</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                                       TEXT\n",
       "0     PLAIN-1      why deep fried foods may cause cancer\n",
       "1  PLAIN-1007                                        ddt\n",
       "2   PLAIN-101  how to treat multiple sclerosis with diet\n",
       "3  PLAIN-1017                             detoxification\n",
       "4  PLAIN-1027                         dietary guidelines"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read queries \n",
    "queries = pd.read_csv('nfcorpus/dev.titles.queries', sep='\\t', names=['ID', 'TEXT'])\n",
    "queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['alkylphenols', 'human', 'milk', 'relations', 'dietary', 'habits',\n",
       "       'central', 'taiwan', 'pubmed', 'ncbi',\n",
       "       ...\n",
       "       'tuscany', 'studies-depression', 'suicides', 'eurosave',\n",
       "       'self-inflicted', 'eurostat', 'upward', 'suicide-recording', 'scarcity',\n",
       "       'trim-and-fill'],\n",
       "      dtype='object', length=26951)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create vocab\n",
    "vocab = tf_idf_matrix.columns\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26951,)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_vect = np.zeros(vocab.shape)\n",
    "q_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#create query vectors\n",
    "query_vectors = {}\n",
    "for index, row in queries.iterrows():    \n",
    "    q_vect = np.zeros(vocab.shape)\n",
    "    t_q = tokenize(q)\n",
    "    q = row['TEXT']\n",
    "    i=0\n",
    "    for t in vocab:\n",
    "        if t in t_q:\n",
    "            q_vect[i] = 1\n",
    "        i+=1\n",
    "    query_vectors[index] = [row['ID'],q_vect]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(sum(query_vectors[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the word does not exist in the vocab\n"
     ]
    }
   ],
   "source": [
    "s = \"may\"\n",
    "if s in vocab:\n",
    "    print(\"the word exists in the vocab\")\n",
    "else:\n",
    "    print(\"the word does not exist in the vocab\")\n",
    "    \n",
    "#some of the words that exist in the query don't exist in our vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (26951,) and (188657,) not aligned: 26951 (dim 0) != 188657 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-82aedcfc3b8e>\u001b[0m in \u001b[0;36mcosine_similarity\u001b[1;34m(v1, v2)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Creating cosine similarity table (should be 3193 x 3193)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mdot_product\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mvector_magnitude\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mvector_magnitude\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf_idf_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf_idf_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtf_idf_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-82aedcfc3b8e>\u001b[0m in \u001b[0;36mdot_product\u001b[1;34m(v1, v2)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdot_product\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Creating cosine similarity table (should be 3193 x 3193)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (26951,) and (188657,) not aligned: 26951 (dim 0) != 188657 (dim 0)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#calculate cosine similarity for q[0] and other documents\n",
    "for doc in doc_vectors:\n",
    "    print(cosine_similarity(doc, query_vectors[0][1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
