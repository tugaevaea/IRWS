{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss                   # make faiss available\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import scipy.sparse as sp\n",
    "import collections\n",
    "import math\n",
    "import copy\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic 4: Efficient Vector Space Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MED-118</td>\n",
       "      <td>alkylphenols human milk relations dietary habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MED-329</td>\n",
       "      <td>phosphate vascular toxin pubmed ncbi abstract ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MED-330</td>\n",
       "      <td>dietary phosphorus acutely impairs endothelial...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MED-332</td>\n",
       "      <td>public health impact dietary phosphorus excess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MED-334</td>\n",
       "      <td>differences total vitro digestible phosphorus ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                               TEXT\n",
       "0  MED-118  alkylphenols human milk relations dietary habi...\n",
       "1  MED-329  phosphate vascular toxin pubmed ncbi abstract ...\n",
       "2  MED-330  dietary phosphorus acutely impairs endothelial...\n",
       "3  MED-332  public health impact dietary phosphorus excess...\n",
       "4  MED-334  differences total vitro digestible phosphorus ..."
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.read_csv('nfcorpus/dev.docs', sep='\\t', names=['ID', 'TEXT'])\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create token list out of document\n",
    "def tokenize(string):\n",
    "    return string.split()\n",
    "\n",
    "# apply term frequencies for each a single string (document)\n",
    "def tf(string): \n",
    "    # create bag of words from the string\n",
    "    bow = tokenize(string)\n",
    "    \n",
    "    tf_dict = {}\n",
    "    for word in bow:\n",
    "        if word in tf_dict:\n",
    "            tf_dict[word] += 1\n",
    "        else:\n",
    "            tf_dict[word] = 1\n",
    "            \n",
    "    for word in tf_dict:\n",
    "        tf_dict[word] = tf_dict[word] / len(bow)\n",
    "    \n",
    "    return tf_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008547008547008548"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We then call our function on every doc and store all these tf dictionaries. \n",
    "tf_dict = {}\n",
    "for index, row in corpus.iterrows():\n",
    "    doc_dict = tf(row['TEXT'])\n",
    "    tf_dict[index] = doc_dict\n",
    "\n",
    "# test if tfDict was created correctly\n",
    "tf_dict[0][\"alkylphenols\"]\n",
    "# alkylphenols for doc 0 : 0.008547008547008548"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3193\n"
     ]
    }
   ],
   "source": [
    "# total number of documents in corpus\n",
    "no_of_docs = len(corpus.index)\n",
    "print(no_of_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# term - key, number of docs term occured in\n",
    "def count_occurances():\n",
    "    count_dict = {}\n",
    "    for key in tf_dict:\n",
    "        for key in tf_dict[key]:\n",
    "            if key in count_dict:\n",
    "                count_dict[key] += 1\n",
    "            else:\n",
    "                count_dict[key] = 1\n",
    "    return count_dict\n",
    "\n",
    "# test if count_occurances works\n",
    "count_oc = count_occurances()\n",
    "count_oc[\"alkylphenols\"] # checked with Elina, good\n",
    "\n",
    "# number of alkylphenols occurence in entire corpus = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.122806043659469"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# having total number of documents and number of occurances of each word in entire corpus we can calculate \n",
    "# idf for each term as log(total # of documents / # of documents with term in it)\n",
    "\n",
    "# idf is calculated per each term, thus we create dictionary with term as a key and idf as a value\n",
    "def idf():\n",
    "    \n",
    "    idf_dict = {}\n",
    "    for key in count_oc:\n",
    "        idf_dict[key] = math.log(no_of_docs/count_oc[key])\n",
    "    return idf_dict\n",
    "\n",
    "idf = idf()\n",
    "\n",
    "# test if idf function works\n",
    "idf[\"alkylphenols\"]\n",
    "\n",
    "# alkylphenols idf = 6.122806043659469"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result from def:\n",
      "0.05233167558683307\n",
      "Manual result:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.05233167558683307"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cosntructing the final tf-idf dictionary; tf-idf is calculated as tf-idf(t, d) = tf(t, d) * idf(t)\n",
    "# so for each key in tf dict we have to miltiply it with corresponsinf idf value\n",
    "\n",
    "def tf_idf():\n",
    "    d = copy.deepcopy(tf_dict)\n",
    "    for doc, value in d.items():\n",
    "        for word, value in d[doc].items():\n",
    "            d[doc][word] = value * idf[word]\n",
    "    return d\n",
    "\n",
    "# test if tf_idf works\n",
    "a = tf_idf()\n",
    "print('Result from def:')\n",
    "print(a[0][\"alkylphenols\"])\n",
    "\n",
    "# excpected result for (term, doc) --> (alkylphenols, 0) =  0.008547008547008548 * 6.122806043659469 = 0.05\n",
    "print('Manual result:')\n",
    "idf[\"alkylphenols\"] * tf_dict[0][\"alkylphenols\"]\n",
    "\n",
    "# it works :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alkylphenols</th>\n",
       "      <th>human</th>\n",
       "      <th>milk</th>\n",
       "      <th>relations</th>\n",
       "      <th>dietary</th>\n",
       "      <th>habits</th>\n",
       "      <th>central</th>\n",
       "      <th>taiwan</th>\n",
       "      <th>pubmed</th>\n",
       "      <th>ncbi</th>\n",
       "      <th>...</th>\n",
       "      <th>tuscany</th>\n",
       "      <th>studies-depression</th>\n",
       "      <th>suicides</th>\n",
       "      <th>eurosave</th>\n",
       "      <th>self-inflicted</th>\n",
       "      <th>eurostat</th>\n",
       "      <th>upward</th>\n",
       "      <th>suicide-recording</th>\n",
       "      <th>scarcity</th>\n",
       "      <th>trim-and-fill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.052332</td>\n",
       "      <td>0.041372</td>\n",
       "      <td>0.079999</td>\n",
       "      <td>0.046407</td>\n",
       "      <td>0.021178</td>\n",
       "      <td>0.060818</td>\n",
       "      <td>0.029952</td>\n",
       "      <td>0.047041</td>\n",
       "      <td>0.002278</td>\n",
       "      <td>0.002334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001777</td>\n",
       "      <td>0.001820</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022663</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001625</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001549</td>\n",
       "      <td>0.001588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26951 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   alkylphenols     human      milk  relations   dietary    habits   central  \\\n",
       "0      0.052332  0.041372  0.079999   0.046407  0.021178  0.060818  0.029952   \n",
       "1      0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  0.000000   \n",
       "2      0.000000  0.000000  0.000000   0.000000  0.028372  0.000000  0.000000   \n",
       "3      0.000000  0.000000  0.000000   0.000000  0.022663  0.000000  0.000000   \n",
       "4      0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "     taiwan    pubmed      ncbi  ...  tuscany  studies-depression  suicides  \\\n",
       "0  0.047041  0.002278  0.002334  ...      0.0                 0.0       0.0   \n",
       "1  0.000000  0.001777  0.001820  ...      0.0                 0.0       0.0   \n",
       "2  0.000000  0.000000  0.000000  ...      0.0                 0.0       0.0   \n",
       "3  0.000000  0.001625  0.001665  ...      0.0                 0.0       0.0   \n",
       "4  0.000000  0.001549  0.001588  ...      0.0                 0.0       0.0   \n",
       "\n",
       "   eurosave  self-inflicted  eurostat  upward  suicide-recording  scarcity  \\\n",
       "0       0.0             0.0       0.0     0.0                0.0       0.0   \n",
       "1       0.0             0.0       0.0     0.0                0.0       0.0   \n",
       "2       0.0             0.0       0.0     0.0                0.0       0.0   \n",
       "3       0.0             0.0       0.0     0.0                0.0       0.0   \n",
       "4       0.0             0.0       0.0     0.0                0.0       0.0   \n",
       "\n",
       "   trim-and-fill  \n",
       "0            0.0  \n",
       "1            0.0  \n",
       "2            0.0  \n",
       "3            0.0  \n",
       "4            0.0  \n",
       "\n",
       "[5 rows x 26951 columns]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First we have to build TF-IDF matrix based on obtain dictionary. \n",
    "# Rows will correspond to docs in the corpus, while columns will represent unique words\n",
    "\n",
    "#              word1       ...          wordn\n",
    "#  doc1   tf_idf_value   ...      tf_idf_value\n",
    "#  ...    tf_idf_value   ...      tf_idf_value\n",
    "#  docn   tf_idf_value   ...      tf_idf_value\n",
    "#\n",
    "\n",
    "tf_idf_matrix = pd.DataFrame.from_dict(a, orient = 'index').fillna(0) # if word does not appear in doc we change NaN to\n",
    "tf_idf_matrix = tf_idf_matrix.sort_index()\n",
    "tf_idf_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alkylphenols         0.052332\n",
      "human                0.041372\n",
      "milk                 0.079999\n",
      "relations            0.046407\n",
      "dietary              0.021178\n",
      "                       ...   \n",
      "eurostat             0.000000\n",
      "upward               0.000000\n",
      "suicide-recording    0.000000\n",
      "scarcity             0.000000\n",
      "trim-and-fill        0.000000\n",
      "Name: 0, Length: 26951, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9999999999999996"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we have to compare docs by computing cosine similarity between each vector (row) in dataframe\n",
    "# For that we need to obtain 1. vector magintude 2. dot product between two vectors\n",
    "\n",
    "def vector_magnitude(v):\n",
    "    return np.linalg.norm(v)\n",
    "\n",
    "def dot_product(v1, v2):\n",
    "    return np.dot(v1,v2)\n",
    "\n",
    "# Creating cosine similarity table (should be 3193 x 3193)\n",
    "def cosine_similarity(v1, v2):\n",
    "    return dot_product(v1, v2)/ (vector_magnitude(v1) * vector_magnitude(v2))\n",
    "print(tf_idf_matrix.iloc[0])\n",
    "cosine_similarity(tf_idf_matrix.iloc[0],tf_idf_matrix.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preclustering suggested in the lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alkylphenols</th>\n",
       "      <th>human</th>\n",
       "      <th>milk</th>\n",
       "      <th>relations</th>\n",
       "      <th>dietary</th>\n",
       "      <th>habits</th>\n",
       "      <th>central</th>\n",
       "      <th>taiwan</th>\n",
       "      <th>pubmed</th>\n",
       "      <th>ncbi</th>\n",
       "      <th>...</th>\n",
       "      <th>tuscany</th>\n",
       "      <th>studies-depression</th>\n",
       "      <th>suicides</th>\n",
       "      <th>eurosave</th>\n",
       "      <th>self-inflicted</th>\n",
       "      <th>eurostat</th>\n",
       "      <th>upward</th>\n",
       "      <th>suicide-recording</th>\n",
       "      <th>scarcity</th>\n",
       "      <th>trim-and-fill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002358</td>\n",
       "      <td>0.002417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001813</td>\n",
       "      <td>0.001858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010084</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001666</td>\n",
       "      <td>0.001707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001240</td>\n",
       "      <td>0.001270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.075634</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038716</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002082</td>\n",
       "      <td>0.002133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26951 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    alkylphenols     human  milk  relations   dietary  habits  central  \\\n",
       "39           0.0  0.000000   0.0        0.0  0.000000     0.0      0.0   \n",
       "50           0.0  0.000000   0.0        0.0  0.000000     0.0      0.0   \n",
       "57           0.0  0.010084   0.0        0.0  0.000000     0.0      0.0   \n",
       "64           0.0  0.000000   0.0        0.0  0.000000     0.0      0.0   \n",
       "93           0.0  0.075634   0.0        0.0  0.038716     0.0      0.0   \n",
       "\n",
       "    taiwan    pubmed      ncbi  ...  tuscany  studies-depression  suicides  \\\n",
       "39     0.0  0.002358  0.002417  ...      0.0                 0.0       0.0   \n",
       "50     0.0  0.001813  0.001858  ...      0.0                 0.0       0.0   \n",
       "57     0.0  0.001666  0.001707  ...      0.0                 0.0       0.0   \n",
       "64     0.0  0.001240  0.001270  ...      0.0                 0.0       0.0   \n",
       "93     0.0  0.002082  0.002133  ...      0.0                 0.0       0.0   \n",
       "\n",
       "    eurosave  self-inflicted  eurostat  upward  suicide-recording  scarcity  \\\n",
       "39       0.0             0.0       0.0     0.0                0.0       0.0   \n",
       "50       0.0             0.0       0.0     0.0                0.0       0.0   \n",
       "57       0.0             0.0       0.0     0.0                0.0       0.0   \n",
       "64       0.0             0.0       0.0     0.0                0.0       0.0   \n",
       "93       0.0             0.0       0.0     0.0                0.0       0.0   \n",
       "\n",
       "    trim-and-fill  \n",
       "39            0.0  \n",
       "50            0.0  \n",
       "57            0.0  \n",
       "64            0.0  \n",
       "93            0.0  \n",
       "\n",
       "[5 rows x 26951 columns]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set number of clusters at initialisation time\n",
    "sqrt_n = round(math.sqrt(no_of_docs))\n",
    "\n",
    "#we randomly select sqrt(N) documents from the corpus, which we call leaders\n",
    "leaders = tf_idf_matrix.sample(sqrt_n)\n",
    "leaders = leaders.sort_index()\n",
    "leaders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For every other document in the collection\n",
    "# 1. Compute the similarities (cosine of the angle between TF-IDF vectors) with all leaders\n",
    "# 2. Add the document to the cluster of the most similar leader\n",
    "\n",
    "cluster_list = []\n",
    "\n",
    "for i in range(sqrt_n):\n",
    "    cluster_list.append([])\n",
    "\n",
    "for i in range(no_of_docs):\n",
    "    cosines = []\n",
    "    for j in leaders.index:\n",
    "        cosines.append(cosine_similarity(tf_idf_matrix.loc[i],leaders.loc[j]))\n",
    "    m = max(cosines)\n",
    "    index_of_max = [l for l, b in enumerate(cosines) if b == m]\n",
    "    cluster_list[index_of_max[0]].append(i) #if there are two equal max values of cosine similarity use the smaller index by default\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[39, 270, 406, 415, 889, 1896, 3131]]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_list[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all docs are distributed to the clusters\n"
     ]
    }
   ],
   "source": [
    "# check of total docs (every doc should be included in exactly one cluster)\n",
    "total = 0\n",
    "for i in range(len(cluster_list)):\n",
    "    total = total + len(cluster_list[i])\n",
    "\n",
    "if total == no_of_docs:\n",
    "    print('all docs are distributed to the clusters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct function, which uses query q(should be already in the vector form) as input, required similarity of the doc to be retrieved - threshold, and\n",
    "#necessary number of documents to be retrieved - K (5 most similar docs in the cluster by default)\n",
    "\n",
    "def ir_preclustering(q, threshold = 0, K = 5): \n",
    "    sim_to_leaders = [] #array of cosine similarities of q to leaders\n",
    "    retrieved_docs = [] #array of the most similar docs to be returned by the function\n",
    "    \n",
    "    for i in leaders.index:\n",
    "        sim_to_leaders.append(cosine_similarity(q,leaders.iloc[j]))\n",
    "    m = max(sim_to_leaders)\n",
    "    index_of_max = [l for l, b in enumerate(cosines) if b == m] #odinal number of most similar leader => use this cluster\n",
    "    \n",
    "    sim_to_docs = [] #array of cosine similarities of q to all docs in the chosen cluster\n",
    "    for doc in cluster_list[index_of_max]:\n",
    "        sim_to_docs.append(cosine_similarity(q,tf_idf_matrix.iloc[doc]))\n",
    "        \n",
    "    ins = np.argsort(sim_to_docs) #returns the indices that would sort an array of similarities to docs in accending order\n",
    "    \n",
    "    if threshold == 0: #proceed only with K\n",
    "        for k in range(K):\n",
    "            retrieved_docs.append(cluster_list[m][-k-1])\n",
    "\n",
    "        df_retrieved_docs = tf_idf_matrix.iloc[retrieved_docs] #construct the dataframe of retrieved docs to be returned by the function\n",
    "    \n",
    "    else:\n",
    "        if sim_to_docs[ins[0]] < threshold:\n",
    "            print('no documents satisfy necessary level of threshold similarity')\n",
    "            return None\n",
    "        \n",
    "        for sim in sim_to_docs:\n",
    "            if sim >= threshold:\n",
    "                retrieved_docs.append(cluster_list[m][sim_to_docs.index(sim)])\n",
    "            if len(retrieved_docs) < K:\n",
    "                print('number of documents that satisfy threshold similarity is less than required \\(less than K\\)')\n",
    "            df_retrieved_docs = tf_idf_matrix.iloc[retrieved_docs]\n",
    "        \n",
    "    return df_retrieved_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "       n_clusters=57, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set number of clusters at initialisation time\n",
    "sqrt_n = round(math.sqrt(no_of_docs))\n",
    "\n",
    "#Run the clustering algorithm\n",
    "estimator = KMeans(n_clusters = sqrt_n)\n",
    "model = estimator.fit(tf_idf_matrix)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate cluster predictions and store in y_hat\n",
    "y_hat = estimator.predict(tf_idf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00,  5.47939477e-03,  4.33680869e-19, ...,\n",
       "        -1.69406589e-21,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  4.33680869e-19, ...,\n",
       "        -1.69406589e-21,  0.00000000e+00,  0.00000000e+00],\n",
       "       ...,\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  2.55303422e-03,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 2.71050543e-20,  1.40550316e-03,  8.67361738e-19, ...,\n",
       "        -3.38813179e-21,  0.00000000e+00,  0.00000000e+00]])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since we have 57 clusters, we are going to compare the query vector with 57 vectors of cluster centroids\n",
    "#All of cluster centroids are stored in the attribute cluster_centers\n",
    "centers = np.array(model.cluster_centers_)\n",
    "centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
