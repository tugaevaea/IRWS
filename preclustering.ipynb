{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/MacBook/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss                   # make faiss available\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import scipy.sparse as sp\n",
    "import collections\n",
    "import math\n",
    "import copy\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import itertools\n",
    "import more_itertools as mit\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic 4: Efficient Vector Space Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MED-118</td>\n",
       "      <td>alkylphenols human milk relations dietary habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MED-329</td>\n",
       "      <td>phosphate vascular toxin pubmed ncbi abstract ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MED-330</td>\n",
       "      <td>dietary phosphorus acutely impairs endothelial...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MED-332</td>\n",
       "      <td>public health impact dietary phosphorus excess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MED-334</td>\n",
       "      <td>differences total vitro digestible phosphorus ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                               TEXT\n",
       "0  MED-118  alkylphenols human milk relations dietary habi...\n",
       "1  MED-329  phosphate vascular toxin pubmed ncbi abstract ...\n",
       "2  MED-330  dietary phosphorus acutely impairs endothelial...\n",
       "3  MED-332  public health impact dietary phosphorus excess...\n",
       "4  MED-334  differences total vitro digestible phosphorus ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.read_csv('nfcorpus/dev.docs', sep='\\t', names=['ID', 'TEXT'])\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for corpus preprocessing: stemming\n",
    "\n",
    "def preprocess_corpus(data):\n",
    "\n",
    "    ps = PorterStemmer()\n",
    "\n",
    "    def stemSentence(sentence,ps):\n",
    "        token_words = word_tokenize(sentence)\n",
    "        stem_sentence = []\n",
    "        for word in token_words:\n",
    "            stem_sentence.append(ps.stem(word))\n",
    "            stem_sentence.append(\" \")\n",
    "        return \"\".join(stem_sentence)\n",
    "\n",
    "    data['TEXT'] = data.apply(lambda x: stemSentence(x['TEXT'],ps), axis=1)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MED-118</td>\n",
       "      <td>alkylphenol human milk relat dietari habit cen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MED-329</td>\n",
       "      <td>phosphat vascular toxin pubm ncbi abstract ele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MED-330</td>\n",
       "      <td>dietari phosphoru acut impair endotheli functi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MED-332</td>\n",
       "      <td>public health impact dietari phosphoru excess ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MED-334</td>\n",
       "      <td>differ total vitro digest phosphoru content pl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                               TEXT\n",
       "0  MED-118  alkylphenol human milk relat dietari habit cen...\n",
       "1  MED-329  phosphat vascular toxin pubm ncbi abstract ele...\n",
       "2  MED-330  dietari phosphoru acut impair endotheli functi...\n",
       "3  MED-332  public health impact dietari phosphoru excess ...\n",
       "4  MED-334  differ total vitro digest phosphoru content pl..."
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = preprocess_corpus(corpus)\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply term frequencies for each a single string (document)\n",
    "def tf(qstring):\n",
    "    \n",
    "    \n",
    "    # create token list out of document\n",
    "    def tokenize(qstring):\n",
    "        return qstring.split()\n",
    "\n",
    "    # create bag of words from the string\n",
    "    bow = tokenize(qstring)\n",
    "    \n",
    "    tf_dict = {}\n",
    "    for word in bow:\n",
    "        if word in tf_dict:\n",
    "            tf_dict[word] += 1\n",
    "        else:\n",
    "            tf_dict[word] = 1\n",
    "            \n",
    "    for word in tf_dict:\n",
    "        tf_dict[word] = 1 + math.log(tf_dict[word])\n",
    "    \n",
    "    return tf_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We then call our function on every doc and store all these tf dictionaries. \n",
    "tf_dict = {}\n",
    "for index, row in corpus.iterrows():\n",
    "    doc_dict = tf(row['TEXT'])\n",
    "    tf_dict[index] = doc_dict\n",
    "\n",
    "# test if tfDict was created correctly\n",
    "tf_dict[0][\"alkylphenol\"]\n",
    "# alkylphenols for doc 0 : 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3193\n"
     ]
    }
   ],
   "source": [
    "# total number of documents in corpus\n",
    "no_of_docs = len(corpus.index)\n",
    "print(no_of_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# term - key, number of docs term occured in\n",
    "def count_occurances():\n",
    "    count_dict = {}\n",
    "    for key in tf_dict:\n",
    "        for key in tf_dict[key]:\n",
    "            if key in count_dict:\n",
    "                count_dict[key] += 1\n",
    "            else:\n",
    "                count_dict[key] = 1\n",
    "    return count_dict\n",
    "\n",
    "# test if count_occurances works\n",
    "count_oc = count_occurances()\n",
    "count_oc[\"alkylphenol\"] \n",
    "\n",
    "# number of alkylphenols occurence in entire corpus = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.122806043659469"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# having total number of documents and number of occurances of each word in entire corpus we can calculate \n",
    "# idf for each term as log(total # of documents / # of documents with term in it)\n",
    "\n",
    "# idf is calculated per each term, thus we create dictionary with term as a key and idf as a value\n",
    "def idf():\n",
    "    \n",
    "    idf_dict = {}\n",
    "    for key in count_oc:\n",
    "        idf_dict[key] = math.log(no_of_docs/count_oc[key])\n",
    "    return idf_dict\n",
    "\n",
    "idf = idf()\n",
    "\n",
    "# test if idf function works\n",
    "idf[\"alkylphenol\"]\n",
    "\n",
    "# alkylphenols idf = 6.122806043659469"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result from def:\n",
      "6.122806043659469\n",
      "Manual result:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.122806043659469"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cosntructing the final tf-idf dictionary; tf-idf is calculated as tf-idf(t, d) = tf(t, d) * idf(t)\n",
    "# so for each key in tf dict we have to miltiply it with corresponsinf idf value\n",
    "\n",
    "def tf_idf():\n",
    "    d = copy.deepcopy(tf_dict)\n",
    "    for doc, value in d.items():\n",
    "        for word, value in d[doc].items():\n",
    "            d[doc][word] = value * idf[word]\n",
    "    return d\n",
    "\n",
    "# test if tf_idf works\n",
    "a = tf_idf()\n",
    "print('Result from def:')\n",
    "print(a[0][\"alkylphenol\"])\n",
    "\n",
    "# excpected result for (term, doc) --> (alkylphenols, 0) =  0.008547008547008548 * 6.122806043659469 = 0.05\n",
    "print('Manual result:')\n",
    "idf[\"alkylphenol\"] * tf_dict[0][\"alkylphenol\"]\n",
    "\n",
    "# it works :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alkylphenol</th>\n",
       "      <th>human</th>\n",
       "      <th>milk</th>\n",
       "      <th>relat</th>\n",
       "      <th>dietari</th>\n",
       "      <th>habit</th>\n",
       "      <th>central</th>\n",
       "      <th>taiwan</th>\n",
       "      <th>pubm</th>\n",
       "      <th>ncbi</th>\n",
       "      <th>...</th>\n",
       "      <th>six-year</th>\n",
       "      <th>inchianti</th>\n",
       "      <th>tuscani</th>\n",
       "      <th>studies-depress</th>\n",
       "      <th>eurosav</th>\n",
       "      <th>self-inflict</th>\n",
       "      <th>eurostat</th>\n",
       "      <th>suicide-record</th>\n",
       "      <th>scarciti</th>\n",
       "      <th>trim-and-fil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.122806</td>\n",
       "      <td>2.886416</td>\n",
       "      <td>6.547579</td>\n",
       "      <td>2.90854</td>\n",
       "      <td>2.095849</td>\n",
       "      <td>5.898499</td>\n",
       "      <td>3.473596</td>\n",
       "      <td>5.503767</td>\n",
       "      <td>0.266507</td>\n",
       "      <td>0.27307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266507</td>\n",
       "      <td>0.27307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.597750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.597750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266507</td>\n",
       "      <td>0.27307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266507</td>\n",
       "      <td>0.27307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 19930 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   alkylphenol     human      milk    relat   dietari     habit   central  \\\n",
       "0     6.122806  2.886416  6.547579  2.90854  2.095849  5.898499  3.473596   \n",
       "1     0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "2     0.000000  0.000000  0.000000  0.00000  2.597750  0.000000  0.000000   \n",
       "3     0.000000  0.000000  0.000000  0.00000  2.597750  0.000000  0.000000   \n",
       "4     0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000   \n",
       "\n",
       "     taiwan      pubm     ncbi  ...  six-year  inchianti  tuscani  \\\n",
       "0  5.503767  0.266507  0.27307  ...       0.0        0.0      0.0   \n",
       "1  0.000000  0.266507  0.27307  ...       0.0        0.0      0.0   \n",
       "2  0.000000  0.000000  0.00000  ...       0.0        0.0      0.0   \n",
       "3  0.000000  0.266507  0.27307  ...       0.0        0.0      0.0   \n",
       "4  0.000000  0.266507  0.27307  ...       0.0        0.0      0.0   \n",
       "\n",
       "   studies-depress  eurosav  self-inflict  eurostat  suicide-record  scarciti  \\\n",
       "0              0.0      0.0           0.0       0.0             0.0       0.0   \n",
       "1              0.0      0.0           0.0       0.0             0.0       0.0   \n",
       "2              0.0      0.0           0.0       0.0             0.0       0.0   \n",
       "3              0.0      0.0           0.0       0.0             0.0       0.0   \n",
       "4              0.0      0.0           0.0       0.0             0.0       0.0   \n",
       "\n",
       "   trim-and-fil  \n",
       "0           0.0  \n",
       "1           0.0  \n",
       "2           0.0  \n",
       "3           0.0  \n",
       "4           0.0  \n",
       "\n",
       "[5 rows x 19930 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First we have to build TF-IDF matrix based on obtain dictionary. \n",
    "# Rows will correspond to docs in the corpus, while columns will represent unique words\n",
    "\n",
    "#              word1       ...          wordn\n",
    "#  doc1   tf_idf_value   ...      tf_idf_value\n",
    "#  ...    tf_idf_value   ...      tf_idf_value\n",
    "#  docn   tf_idf_value   ...      tf_idf_value\n",
    "#\n",
    "\n",
    "tf_idf_matrix = pd.DataFrame.from_dict(a, orient = 'index').fillna(0) # if word does not appear in doc we change NaN to\n",
    "tf_idf_matrix = tf_idf_matrix.sort_index()\n",
    "tf_idf_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alkylphenol       6.122806\n",
      "human             2.886416\n",
      "milk              6.547579\n",
      "relat             2.908540\n",
      "dietari           2.095849\n",
      "                    ...   \n",
      "self-inflict      0.000000\n",
      "eurostat          0.000000\n",
      "suicide-record    0.000000\n",
      "scarciti          0.000000\n",
      "trim-and-fil      0.000000\n",
      "Name: 0, Length: 19930, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we have to compare docs by computing cosine similarity between each vector (row) in dataframe\n",
    "# For that we need to obtain 1. vector magintude 2. dot product between two vectors\n",
    "\n",
    "def vector_magnitude(v):\n",
    "    return np.linalg.norm(v)\n",
    "\n",
    "def dot_product(v1, v2):\n",
    "    return np.dot(v1,v2)\n",
    "\n",
    "# Creating cosine similarity table (should be 3193 x 3193)\n",
    "def cosine_similarity(v1, v2):\n",
    "    return dot_product(v1, v2)/ (vector_magnitude(v1) * vector_magnitude(v2))\n",
    "print(tf_idf_matrix.iloc[0])\n",
    "cosine_similarity(tf_idf_matrix.iloc[0],tf_idf_matrix.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preclustering suggested in the lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alkylphenol</th>\n",
       "      <th>human</th>\n",
       "      <th>milk</th>\n",
       "      <th>relat</th>\n",
       "      <th>dietari</th>\n",
       "      <th>habit</th>\n",
       "      <th>central</th>\n",
       "      <th>taiwan</th>\n",
       "      <th>pubm</th>\n",
       "      <th>ncbi</th>\n",
       "      <th>...</th>\n",
       "      <th>six-year</th>\n",
       "      <th>inchianti</th>\n",
       "      <th>tuscani</th>\n",
       "      <th>studies-depress</th>\n",
       "      <th>eurosav</th>\n",
       "      <th>self-inflict</th>\n",
       "      <th>eurostat</th>\n",
       "      <th>suicide-record</th>\n",
       "      <th>scarciti</th>\n",
       "      <th>trim-and-fil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.375393</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.237842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266507</td>\n",
       "      <td>0.27307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266507</td>\n",
       "      <td>0.27307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266507</td>\n",
       "      <td>0.27307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.230072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266507</td>\n",
       "      <td>0.27307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 19930 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alkylphenol     human  milk  relat   dietari  habit  central  taiwan  \\\n",
       "276          0.0  1.375393   0.0    0.0  1.237842    0.0      0.0     0.0   \n",
       "400          0.0  0.000000   0.0    0.0  0.000000    0.0      0.0     0.0   \n",
       "518          0.0  0.000000   0.0    0.0  0.000000    0.0      0.0     0.0   \n",
       "523          0.0  0.000000   0.0    0.0  0.000000    0.0      0.0     0.0   \n",
       "544          0.0  0.000000   0.0    0.0  3.230072    0.0      0.0     0.0   \n",
       "\n",
       "         pubm     ncbi  ...  six-year  inchianti  tuscani  studies-depress  \\\n",
       "276  0.266507  0.27307  ...       0.0        0.0      0.0              0.0   \n",
       "400  0.266507  0.27307  ...       0.0        0.0      0.0              0.0   \n",
       "518  0.266507  0.27307  ...       0.0        0.0      0.0              0.0   \n",
       "523  0.000000  0.00000  ...       0.0        0.0      0.0              0.0   \n",
       "544  0.266507  0.27307  ...       0.0        0.0      0.0              0.0   \n",
       "\n",
       "     eurosav  self-inflict  eurostat  suicide-record  scarciti  trim-and-fil  \n",
       "276      0.0           0.0       0.0             0.0       0.0           0.0  \n",
       "400      0.0           0.0       0.0             0.0       0.0           0.0  \n",
       "518      0.0           0.0       0.0             0.0       0.0           0.0  \n",
       "523      0.0           0.0       0.0             0.0       0.0           0.0  \n",
       "544      0.0           0.0       0.0             0.0       0.0           0.0  \n",
       "\n",
       "[5 rows x 19930 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set number of clusters at initialisation time\n",
    "sqrt_n = round(math.sqrt(no_of_docs))\n",
    "\n",
    "#we randomly select sqrt(N) documents from the corpus, which we call leaders\n",
    "leaders = tf_idf_matrix.sample(sqrt_n, random_state = 11)\n",
    "leaders = leaders.sort_index()\n",
    "leaders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For every other document in the collection\n",
    "# 1. Compute the similarities (cosine of the angle between TF-IDF vectors) with all leaders\n",
    "# 2. Add the document to the cluster of the most similar leader\n",
    "\n",
    "cluster_list = []\n",
    "\n",
    "for i in range(sqrt_n):\n",
    "    cluster_list.append([])\n",
    "\n",
    "for i in range(no_of_docs):\n",
    "    cosines = []\n",
    "    for j in leaders.index:\n",
    "        cosines.append(cosine_similarity(tf_idf_matrix.loc[i],leaders.loc[j]))\n",
    "    m = max(cosines)\n",
    "    index_of_max = [l for l, b in enumerate(cosines) if b == m]\n",
    "    cluster_list[index_of_max[0]].append(i) #if there are two equal max values of cosine similarity use the smaller index by default\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all docs are distributed to the clusters\n"
     ]
    }
   ],
   "source": [
    "# check of total docs (every doc should be included in exactly one cluster)\n",
    "total = 0\n",
    "for i in range(len(cluster_list)):\n",
    "    total = total + len(cluster_list[i])\n",
    "\n",
    "if total == no_of_docs:\n",
    "    print('all docs are distributed to the clusters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct function, which uses query q(should be already in the vector form) as input, required similarity of the doc to be retrieved - threshold, and\n",
    "#necessary number of documents to be retrieved - K (5 most similar docs in the cluster by default)\n",
    "\n",
    "def ir_preclustering(q, threshold = 0, K = 5): \n",
    "    sim_to_leaders = [] #array of cosine similarities of q to leaders\n",
    "    retrieved_docs = [] #array of the most similar docs to be returned by the function\n",
    "    \n",
    "    for i in range(len(leaders.index)):\n",
    "        sim_to_leaders.append(cosine_similarity(q,leaders.iloc[i]))\n",
    "    m = max(sim_to_leaders)\n",
    "    index_of_max = [l for l, b in enumerate(sim_to_leaders) if b == m] #odinal number of most similar leader => use this cluster\n",
    "    \n",
    "    sim_to_docs = [] #array of cosine similarities of q to all docs in the chosen cluster\n",
    "    for doc in cluster_list[index_of_max[0]]:\n",
    "        sim_to_docs.append(cosine_similarity(q,tf_idf_matrix.iloc[doc]))\n",
    "        \n",
    "    ins = np.argsort(sim_to_docs) #returns the indices that would sort an array of similarities to docs in ascending order\n",
    "    ins = ins[::-1] #but we need descending (most similar in the beginning of the list)\n",
    "    \n",
    "    if threshold == 0: #proceed only with K\n",
    "        if len(ins)>=K:\n",
    "            for k in range(K):\n",
    "                retrieved_docs.append(cluster_list[index_of_max[0]][ins[k]])\n",
    "        else:\n",
    "            K=len(ins)\n",
    "            for k in range(K):\n",
    "                retrieved_docs.append(cluster_list[index_of_max[0]][ins[k]])\n",
    "\n",
    "        \n",
    "    else:\n",
    "        if sim_to_docs[ins[0]] < threshold:\n",
    "            print('no documents satisfy necessary level of threshold similarity')\n",
    "            return None\n",
    "        \n",
    "        for sim in sim_to_docs:\n",
    "            if sim >= threshold:\n",
    "                retrieved_docs.append(cluster_list[index_of_max[0]][sim_to_docs.index(sim)])\n",
    "            if len(retrieved_docs) < K:\n",
    "                print('number of documents that satisfy threshold similarity is less than required \\(less than K\\)')\n",
    "    \n",
    "    return corpus.iloc[retrieved_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# repeat this procedure using FAISS instead of cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FAISS works only with type float32\n",
    "tf_idf_matrix = tf_idf_matrix.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are going to use the same leaders\n",
    "leaders = leaders.astype('float32')\n",
    "index = faiss.IndexFlatL2(len(leaders.columns))\n",
    "index.add(np.ascontiguousarray(leaders.values))\n",
    "\n",
    "#find the nearest leader\n",
    "def ir_preclustering_faiss(q, K = 5, threshold = 0):\n",
    "    q = np.array([q])\n",
    "    D, I = index.search(q, 1) #returning distance and index of the nearest leader\n",
    "    \n",
    "    index2 = faiss.IndexFlatL2(len(leaders.columns)) #train index of the cluster with nearest leader\n",
    "    index2.add(np.ascontiguousarray(tf_idf_matrix.loc[cluster_list[I[0][0]]]))\n",
    "            \n",
    "    \n",
    "    if threshold == 0: #proceed only with K\n",
    "        \n",
    "        if len(cluster_list[I[0][0]]) < K:\n",
    "            print('asked number of documents to be retrieved is larger than the number of documents in the cluster; \\nall documents in the cluster are retrieved')\n",
    "            return corpus.iloc[cluster_list[I[0][0]]]   \n",
    "        else:\n",
    "            DD, II = index2.search(q, K) #returning distances and indexes of the nearest documents (sorted by distance)\n",
    "            return corpus.iloc[II[0]]\n",
    "            \n",
    "        \n",
    "    else:\n",
    "        DD, II = index2.search(q, K)\n",
    "        DD = [1 - x for x in DD] #now DD are not distances, but similarities\n",
    "        \n",
    "        if DD[0] < threshold:\n",
    "            return None\n",
    "        \n",
    "        for sim in DD:\n",
    "            if sim < threshold:\n",
    "                DD.pop(sim)\n",
    "        \n",
    "        if len(DD) < K:\n",
    "                print('number of documents that satisfy threshold similarity is less than required \\(less than K\\)')\n",
    "       \n",
    "        return corpus.iloc[II[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "       n_clusters=57, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=11, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set number of clusters at initialisation time\n",
    "sqrt_n = round(math.sqrt(no_of_docs))\n",
    "\n",
    "#Run the clustering algorithm\n",
    "estimator = KMeans(n_clusters = sqrt_n, random_state = 11)\n",
    "model = estimator.fit(tf_idf_matrix)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([54,  8, 26, ..., 54, 31, 51], dtype=int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generate cluster predictions and store in y_hat\n",
    "y_hat = estimator.predict(tf_idf_matrix) #predicting to which cluster the query belongs\n",
    "y_hat #array of belongings of docs to cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_list_kmeans = []\n",
    "for i in range(sqrt_n):\n",
    "    cluster_list_kmeans.append([])\n",
    "\n",
    "for i in range(no_of_docs):\n",
    "    for j in range(sqrt_n):\n",
    "        if y_hat[i] == j:\n",
    "            cluster_list_kmeans[j].append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1949], [1965]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_list_kmeans[0:2] #in one of the runs of kmeans not very balanced clusters: only one doc in cluster 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00,  1.61351764e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [-9.31322575e-09,  3.63646030e-01,  6.27141595e-01, ...,\n",
       "         1.16415322e-09,  1.16415322e-09,  1.16415322e-09],\n",
       "       ...,\n",
       "       [ 5.58022372e-02,  5.50183833e-01,  4.67874885e-01, ...,\n",
       "         1.36526525e-02,  2.79396772e-09,  2.79396772e-09],\n",
       "       [ 1.86264515e-09,  4.82354194e-01,  3.71828288e-01, ...,\n",
       "        -2.32830644e-10, -2.32830644e-10, -2.32830644e-10],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since we have 57 clusters, we are going to compare the query vector with 57 vectors of cluster centroids\n",
    "#All of cluster centroids are stored in the attribute cluster_centers\n",
    "centers = np.array(model.cluster_centers_)\n",
    "centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#construct function, which uses query q(should be already in the vector form) as input, required similarity of the doc to be retrieved - threshold, and\n",
    "#necessary number of documents to be retrieved - K (5 most similar docs in the cluster by default)\n",
    "\n",
    "def ir_preclustering_kmeans(q, threshold = 0, K = 5): \n",
    "    sim_to_centers = [] #array of cosine similarities of q to leaders\n",
    "    retrieved_docs = [] #array of the most similar docs to be returned by the function\n",
    "    \n",
    "    for i in leaders.index:\n",
    "        sim_to_centers.append(cosine_similarity(q,leaders.iloc[i]))\n",
    "    m = max(sim_to_centers)\n",
    "    index_of_max = [l for l, b in enumerate(sim_to_centers) if b == m] #odinal number of most similar leader => use this cluster\n",
    "    index_of_max = index_of_max[0]\n",
    "    \n",
    "    sim_to_docs = [] #array of cosine similarities of q to all docs in the chosen cluster\n",
    "    for doc in cluster_list[index_of_max]:\n",
    "        sim_to_docs.append(cosine_similarity(q,tf_idf_matrix.iloc[doc]))\n",
    "        \n",
    "    ins = np.argsort(sim_to_docs) #returns the indices that would sort an array of similarities to docs in accending order\n",
    "    \n",
    "    if threshold == 0: #proceed only with K\n",
    "        for k in range(K):\n",
    "            retrieved_docs.append(cluster_list_kmeans[m][-k-1])\n",
    "\n",
    "        df_retrieved_docs = tf_idf_matrix.iloc[retrieved_docs] #construct the dataframe of retrieved docs to be returned by the function\n",
    "    \n",
    "    else:\n",
    "        if sim_to_docs[ins[0]] < threshold:\n",
    "            print('no documents satisfy necessary level of threshold similarity')\n",
    "            return None\n",
    "        \n",
    "        for sim in sim_to_docs:\n",
    "            if sim >= threshold:\n",
    "                retrieved_docs.append(cluster_list_kmeans[m][sim_to_docs.index(sim)])\n",
    "            if len(retrieved_docs) < K:\n",
    "                print('number of documents that satisfy threshold similarity is less than required \\(less than K\\)')\n",
    "            df_retrieved_docs = tf_idf_matrix.iloc[retrieved_docs]\n",
    "        \n",
    "    return df_retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct function, which uses query q(should be already in the vector form) as input, required similarity of the doc to be retrieved - threshold, and\n",
    "#necessary number of documents to be retrieved - K (5 most similar docs in the cluster by default)\n",
    "\n",
    "def ir_preclustering_kmeans(q, threshold = 0, K = 5):\n",
    "\n",
    "    sim_to_centers = [] #array of cosine similarities of q to centers\n",
    "    retrieved_docs = [] #array of the most similar docs to be returned by the function\n",
    "    \n",
    "    for i in range(len(centers.index)):\n",
    "        sim_to_centers.append(cosine_similarity(q,leaders.iloc[i]))\n",
    "    m = max(sim_to_centers)\n",
    "    index_of_max = [l for l, b in enumerate(sim_to_leaders) if b == m] #odinal number of most similar leader => use this cluster\n",
    "    \n",
    "    sim_to_docs = [] #array of cosine similarities of q to all docs in the chosen cluster\n",
    "    for doc in cluster_list_kmeans[index_of_max[0]]:\n",
    "        sim_to_docs.append(cosine_similarity(q,tf_idf_matrix.iloc[doc]))\n",
    "        \n",
    "    ins = np.argsort(sim_to_docs) #returns the indices that would sort an array of similarities to docs in ascending order\n",
    "    ins = ins[::-1] #but we need descending (most similar in the beginning of the list)\n",
    "    \n",
    "    if threshold == 0: #proceed only with K\n",
    "        if len(ins)>=K:\n",
    "            for k in range(K):\n",
    "                retrieved_docs.append(cluster_list_kmeans[index_of_max[0]][ins[k]])\n",
    "        else:\n",
    "            K=len(ins)\n",
    "            for k in range(K):\n",
    "                retrieved_docs.append(cluster_list_kmeans[index_of_max[0]][ins[k]])\n",
    "\n",
    "        \n",
    "    else:\n",
    "        if sim_to_docs[ins[0]] < threshold:\n",
    "            print('no documents satisfy necessary level of threshold similarity')\n",
    "            return None\n",
    "        \n",
    "        for sim in sim_to_docs:\n",
    "            if sim >= threshold:\n",
    "                retrieved_docs.append(cluster_list_kmeans[index_of_max[0]][sim_to_docs.index(sim)])\n",
    "            if len(retrieved_docs) < K:\n",
    "                print('number of documents that satisfy threshold similarity is less than required \\(less than K\\)')\n",
    "    \n",
    "    return corpus.iloc[retrieved_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QUERY_ID</th>\n",
       "      <th>0</th>\n",
       "      <th>DOC_ID</th>\n",
       "      <th>RELEVANCE_LEVEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-2421</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-2422</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-2416</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-2423</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-2417</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-2418</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-4451</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-2420</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-2414</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-4070</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  QUERY_ID  0    DOC_ID  RELEVANCE_LEVEL\n",
       "0  PLAIN-1  0  MED-2421                2\n",
       "1  PLAIN-1  0  MED-2422                2\n",
       "2  PLAIN-1  0  MED-2416                2\n",
       "3  PLAIN-1  0  MED-2423                2\n",
       "4  PLAIN-1  0  MED-2417                2\n",
       "5  PLAIN-1  0  MED-2418                2\n",
       "6  PLAIN-1  0  MED-4451                2\n",
       "7  PLAIN-1  0  MED-2420                2\n",
       "8  PLAIN-1  0  MED-2414                1\n",
       "9  PLAIN-1  0  MED-4070                1"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_relevance = pd.read_csv('nfcorpus/dev.2-1-0.qrel', sep='\\t', names=['QUERY_ID', '0', 'DOC_ID', 'RELEVANCE_LEVEL'])\n",
    "queries_relevance.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>why deep fried foods may cause cancer in the l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PLAIN-1007</td>\n",
       "      <td>ddt - - persistent organic pollutants , indust...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PLAIN-101</td>\n",
       "      <td>how to treat multiple sclerosis with diet mult...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PLAIN-1017</td>\n",
       "      <td>detoxification - - cancer , raw food , heart h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PLAIN-1027</td>\n",
       "      <td>dietary guidelines - - heart disease , cardiov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PLAIN-1038</td>\n",
       "      <td>dogs - - meat , animal products , cats , heart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PLAIN-1049</td>\n",
       "      <td>dr. david spence - - heart health , heart dise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PLAIN-1065</td>\n",
       "      <td>dr. walter kempner - - mortality , heart disea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PLAIN-1077</td>\n",
       "      <td>dulse - - thyroid health , hijiki , sushi , io...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PLAIN-1087</td>\n",
       "      <td>easter island - - mortality , muscle strength ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                                               TEXT\n",
       "0     PLAIN-1  why deep fried foods may cause cancer in the l...\n",
       "1  PLAIN-1007  ddt - - persistent organic pollutants , indust...\n",
       "2   PLAIN-101  how to treat multiple sclerosis with diet mult...\n",
       "3  PLAIN-1017  detoxification - - cancer , raw food , heart h...\n",
       "4  PLAIN-1027  dietary guidelines - - heart disease , cardiov...\n",
       "5  PLAIN-1038  dogs - - meat , animal products , cats , heart...\n",
       "6  PLAIN-1049  dr. david spence - - heart health , heart dise...\n",
       "7  PLAIN-1065  dr. walter kempner - - mortality , heart disea...\n",
       "8  PLAIN-1077  dulse - - thyroid health , hijiki , sushi , io...\n",
       "9  PLAIN-1087  easter island - - mortality , muscle strength ..."
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_text = pd.read_csv('nfcorpus/dev.all.queries', sep='\\t', names=['ID', 'TEXT'])\n",
    "queries_text.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preprocessing of the text of the queries\n",
    "\n",
    "def preprocess_queries(corpus, queries):\n",
    "\n",
    "    def remove_punctuations(text): # remove punctuation\n",
    "        for punctuation in string.punctuation:\n",
    "            text = text.replace(punctuation, '')\n",
    "        return text\n",
    "\n",
    "    def remove_numbers(text): # remove numbers\n",
    "        return re.sub('[0-9]+', '', text)\n",
    "\n",
    "    def lower_case(text): # lower case\n",
    "        text = text.lower()\n",
    "        return text\n",
    "\n",
    "    def tokenize(text): #tokenize\n",
    "        return word_tokenize(text)\n",
    "\n",
    "    stop = set(stopwords.words('english'))\n",
    "    def stop_words(tokens): # stop words\n",
    "        filtered_words = []\n",
    "        for word in tokens:\n",
    "            if word not in stop:\n",
    "                filtered_words.append(word)\n",
    "        return filtered_words\n",
    "\n",
    "    ps = PorterStemmer()\n",
    "    def stemming(tokens, ps): # stemming\n",
    "        return [ps.stem(w) for w in tokens]\n",
    "\n",
    "    def corpus_vocab(corpus):\n",
    "        vocab = []\n",
    "        corpus_tokens = corpus.apply(lambda x: word_tokenize(x['TEXT']), axis=1)\n",
    "        for i, j in corpus_tokens.iteritems():\n",
    "            for token in j:\n",
    "                if token not in vocab:\n",
    "                    vocab.append(token)\n",
    "        return vocab\n",
    "\n",
    "    v = corpus_vocab(corpus)\n",
    "    def filter_query(tokens):\n",
    "        t = []\n",
    "        for token in tokens:\n",
    "            if token in v:\n",
    "                t.append(token)\n",
    "        return t\n",
    "\n",
    "    # apply functions\n",
    "    queries['TEXT'] = queries.apply(lambda x: remove_punctuations(x['TEXT']), axis=1)\n",
    "    queries['TEXT'] = queries.apply(lambda x: remove_numbers(x['TEXT']), axis=1)\n",
    "    queries['TEXT'] = queries.apply(lambda x: lower_case(x['TEXT']), axis=1)\n",
    "    queries['TEXT'] = queries.apply(lambda x: tokenize(x['TEXT']), axis=1)\n",
    "    queries['TEXT'] = queries.apply(lambda x: stop_words(x['TEXT']), axis=1)\n",
    "    queries['TEXT'] = queries.apply(lambda x: stemming(x['TEXT'],ps), axis=1)\n",
    "    queries['TEXT'] = queries.apply(lambda x: filter_query(x['TEXT']), axis=1)\n",
    "\n",
    "    return queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>[deep, fri, food, may, caus, cancer, latest, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PLAIN-1007</td>\n",
       "      <td>[ddt, persist, organ, pollut, industri, toxin,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PLAIN-101</td>\n",
       "      <td>[treat, multipl, sclerosi, diet, multipl, scle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PLAIN-1017</td>\n",
       "      <td>[detoxif, cancer, raw, food, heart, health, he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PLAIN-1027</td>\n",
       "      <td>[dietari, guidelin, heart, diseas, cardiovascu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                                               TEXT\n",
       "0     PLAIN-1  [deep, fri, food, may, caus, cancer, latest, s...\n",
       "1  PLAIN-1007  [ddt, persist, organ, pollut, industri, toxin,...\n",
       "2   PLAIN-101  [treat, multipl, sclerosi, diet, multipl, scle...\n",
       "3  PLAIN-1017  [detoxif, cancer, raw, food, heart, health, he...\n",
       "4  PLAIN-1027  [dietari, guidelin, heart, diseas, cardiovascu..."
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_text = preprocess_queries(corpus, queries_text)\n",
    "queries_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deep',\n",
       " 'fri',\n",
       " 'food',\n",
       " 'may',\n",
       " 'caus',\n",
       " 'cancer',\n",
       " 'latest',\n",
       " 'studi',\n",
       " 'dietari',\n",
       " 'pattern',\n",
       " 'breast',\n",
       " 'cancer',\n",
       " 'risk',\n",
       " 'women',\n",
       " 'healthier',\n",
       " 'eat',\n",
       " 'associ',\n",
       " 'elimin',\n",
       " 'odd',\n",
       " 'breast',\n",
       " 'cancer',\n",
       " 'healthi',\n",
       " 'eat',\n",
       " 'associ',\n",
       " 'time',\n",
       " 'odd',\n",
       " 'includ',\n",
       " 'unhealthi',\n",
       " 'eat',\n",
       " 'pattern',\n",
       " 'consumpt',\n",
       " 'food',\n",
       " 'previous',\n",
       " 'link',\n",
       " 'breast',\n",
       " 'cancer',\n",
       " 'pancreat',\n",
       " 'cancer',\n",
       " 'lung',\n",
       " 'cancer',\n",
       " 'oral',\n",
       " 'throat',\n",
       " 'cancer',\n",
       " 'esophag',\n",
       " 'cancer',\n",
       " 'cancer',\n",
       " 'deep',\n",
       " 'fri',\n",
       " 'food',\n",
       " 'southern',\n",
       " 'bell',\n",
       " 'deep',\n",
       " 'fri',\n",
       " 'food',\n",
       " 'tradit',\n",
       " 'southern',\n",
       " 'diet',\n",
       " 'character',\n",
       " 'high',\n",
       " 'intak',\n",
       " 'cook',\n",
       " 'green',\n",
       " 'bean',\n",
       " 'legum',\n",
       " 'cabbag',\n",
       " 'sweet',\n",
       " 'potato',\n",
       " 'may',\n",
       " 'reduc',\n",
       " 'risk',\n",
       " 'invas',\n",
       " 'breast',\n",
       " 'cancer',\n",
       " 'significantli',\n",
       " 'consumpt',\n",
       " 'food',\n",
       " 'risk',\n",
       " 'prostat',\n",
       " 'cancer',\n",
       " 'research',\n",
       " 'fred',\n",
       " 'hutchinson',\n",
       " 'cancer',\n",
       " 'research',\n",
       " 'center',\n",
       " 'univers',\n",
       " 'washington',\n",
       " 'found',\n",
       " 'eat',\n",
       " 'french',\n",
       " 'fri',\n",
       " 'fri',\n",
       " 'chicken',\n",
       " 'fri',\n",
       " 'fish',\n",
       " 'doughnut',\n",
       " 'associ',\n",
       " 'third',\n",
       " 'greater',\n",
       " 'odd',\n",
       " 'prostat',\n",
       " 'cancer',\n",
       " 'stratifi',\n",
       " 'tumor',\n",
       " 'aggress',\n",
       " 'found',\n",
       " 'slightli',\n",
       " 'stronger',\n",
       " 'associ',\n",
       " 'aggress',\n",
       " 'diseas',\n",
       " 'suggest',\n",
       " 'regular',\n",
       " 'intak',\n",
       " 'food',\n",
       " 'may',\n",
       " 'contribut',\n",
       " 'progress',\n",
       " 'prostat',\n",
       " 'cancer',\n",
       " 'well',\n",
       " 'deep',\n",
       " 'fri',\n",
       " 'food',\n",
       " 'bad',\n",
       " 'heat',\n",
       " 'oil',\n",
       " 'hot',\n",
       " 'gener',\n",
       " 'potenti',\n",
       " 'carcinogen',\n",
       " 'compound',\n",
       " 'carcinogen',\n",
       " 'heterocycl',\n",
       " 'amin',\n",
       " 'polycycl',\n",
       " 'aromat',\n",
       " 'hydrocarbon',\n",
       " 'form',\n",
       " 'muscl',\n",
       " 'chicken',\n",
       " 'fish',\n",
       " 'cook',\n",
       " 'temperatur',\n",
       " 'plant',\n",
       " 'hand',\n",
       " 'form',\n",
       " 'acrylamid',\n",
       " 'video',\n",
       " 'acrylamid',\n",
       " 'back',\n",
       " 'suggest',\n",
       " 'probabl',\n",
       " 'human',\n",
       " 'carcinogen',\n",
       " 'acrylamid',\n",
       " 'french',\n",
       " 'fri',\n",
       " 'studi',\n",
       " 'suggest',\n",
       " 'pregnant',\n",
       " 'women',\n",
       " 'may',\n",
       " 'want',\n",
       " 'cut',\n",
       " 'back',\n",
       " 'french',\n",
       " 'fri',\n",
       " 'protect',\n",
       " 'growth',\n",
       " 'babi',\n",
       " 'bodi',\n",
       " 'brain',\n",
       " 'base',\n",
       " 'studi',\n",
       " 'highlight',\n",
       " 'video',\n",
       " 'cancer',\n",
       " 'risk',\n",
       " 'french',\n",
       " 'fri',\n",
       " 'feed',\n",
       " 'peopl',\n",
       " 'bag',\n",
       " 'potato',\n",
       " 'chip',\n",
       " 'day',\n",
       " 'month',\n",
       " 'acrylamid',\n",
       " 'may',\n",
       " 'caus',\n",
       " 'inflamm',\n",
       " 'well',\n",
       " 'explain',\n",
       " 'purport',\n",
       " 'role',\n",
       " 'cancer',\n",
       " 'progress',\n",
       " 'acrylamid',\n",
       " 'intak',\n",
       " 'associ',\n",
       " 'endometri',\n",
       " 'cancer',\n",
       " 'ovarian',\n",
       " 'cancer',\n",
       " 'lung',\n",
       " 'cancer',\n",
       " 'kidney',\n",
       " 'cancer',\n",
       " 'esophag',\n",
       " 'cancer',\n",
       " 'cancer',\n",
       " 'risk',\n",
       " 'talk',\n",
       " 'taiwanes',\n",
       " 'research',\n",
       " 'examin',\n",
       " 'lifetim',\n",
       " 'cancer',\n",
       " 'risk',\n",
       " 'french',\n",
       " 'fri',\n",
       " 'consumpt',\n",
       " 'research',\n",
       " 'french',\n",
       " 'fri',\n",
       " 'compris',\n",
       " 'greatest',\n",
       " 'percentag',\n",
       " 'contribut',\n",
       " 'acrylamid',\n",
       " 'diet',\n",
       " 'children',\n",
       " 'estim',\n",
       " 'one',\n",
       " 'two',\n",
       " 'boy',\n",
       " 'girl',\n",
       " 'ten',\n",
       " 'thousand',\n",
       " 'develop',\n",
       " 'cancer',\n",
       " 'eat',\n",
       " 'french',\n",
       " 'fri',\n",
       " 'develop',\n",
       " 'eaten',\n",
       " 'french',\n",
       " 'fri',\n",
       " 'bad',\n",
       " 'eat',\n",
       " 'like',\n",
       " 'fri',\n",
       " 'fish',\n",
       " 'fri',\n",
       " 'chicken',\n",
       " 'level',\n",
       " 'cancer',\n",
       " 'risk',\n",
       " 'boy',\n",
       " 'girl',\n",
       " 'associ',\n",
       " 'french',\n",
       " 'fri',\n",
       " 'depend',\n",
       " 'long',\n",
       " 'hot',\n",
       " 'fri',\n",
       " 'europ',\n",
       " 'food',\n",
       " 'industri',\n",
       " 'control',\n",
       " 'fri',\n",
       " 'time',\n",
       " 'decreas',\n",
       " 'acrylamid',\n",
       " 'level',\n",
       " 'subsequ',\n",
       " 'chang',\n",
       " 'acrylamid',\n",
       " 'level',\n",
       " 'french',\n",
       " 'fri',\n",
       " 'research',\n",
       " 'continu',\n",
       " 'urg',\n",
       " 'cook',\n",
       " 'temperatur',\n",
       " 'low',\n",
       " 'possibl',\n",
       " 'cook',\n",
       " 'time',\n",
       " 'short',\n",
       " 'possibl',\n",
       " 'maintain',\n",
       " 'tasti',\n",
       " 'qualiti',\n",
       " 'cours',\n",
       " 'want',\n",
       " 'reduc',\n",
       " 'cancer',\n",
       " 'risk',\n",
       " 'tast',\n",
       " 'good',\n",
       " 'blanch',\n",
       " 'potato',\n",
       " 'reduc',\n",
       " 'acrylamid',\n",
       " 'format',\n",
       " 'potato',\n",
       " 'chip',\n",
       " 'compani',\n",
       " 'complain',\n",
       " 'flavor',\n",
       " 'reduc',\n",
       " 'nutrit',\n",
       " 'properti',\n",
       " 'leach',\n",
       " 'vitamin',\n",
       " 'c',\n",
       " 'reli',\n",
       " 'potato',\n",
       " 'chip',\n",
       " 'vitamin',\n",
       " 'c',\n",
       " 'acrylamid',\n",
       " 'probabl',\n",
       " 'worri',\n",
       " 'heterocycl',\n",
       " 'amin',\n",
       " 'thing',\n",
       " 'counteract',\n",
       " 'effect',\n",
       " 'carcinogen',\n",
       " 'though',\n",
       " 'touch',\n",
       " 'polycycl',\n",
       " 'aromat',\n",
       " 'hydrocarbon',\n",
       " 'meat',\n",
       " 'fume',\n",
       " 'dietari',\n",
       " 'secondhand',\n",
       " 'smoke',\n",
       " 'liquid',\n",
       " 'smoke',\n",
       " 'flavor',\n",
       " 'carcinogen',\n",
       " 'certain',\n",
       " 'fat',\n",
       " 'may',\n",
       " 'play',\n",
       " 'role',\n",
       " 'breast',\n",
       " 'cancer',\n",
       " 'surviv',\n",
       " 'well',\n",
       " 'breast',\n",
       " 'cancer',\n",
       " 'surviv',\n",
       " 'chicken',\n",
       " 'breast',\n",
       " 'cancer',\n",
       " 'surviv',\n",
       " 'tran',\n",
       " 'fat',\n",
       " 'even',\n",
       " 'oil',\n",
       " 'fryer',\n",
       " 'heavili',\n",
       " 'damag',\n",
       " 'refin',\n",
       " 'process',\n",
       " 'multistep',\n",
       " 'process',\n",
       " 'take',\n",
       " 'food',\n",
       " 'seed',\n",
       " 'refin',\n",
       " 'oil',\n",
       " 'leav',\n",
       " 'oxid',\n",
       " 'reactiv',\n",
       " 'fatti',\n",
       " 'acid',\n",
       " 'chemic',\n",
       " 'refin',\n",
       " 'process',\n",
       " 'oxid',\n",
       " 'vegan',\n",
       " 'dha',\n",
       " 'pill',\n",
       " 'make',\n",
       " 'fat',\n",
       " 'harm',\n",
       " 'hope',\n",
       " 'great',\n",
       " 'question',\n",
       " 'well',\n",
       " 'dietari',\n",
       " 'fatti',\n",
       " 'acid',\n",
       " 'dha',\n",
       " 'highest',\n",
       " 'peroxid',\n",
       " 'index',\n",
       " 'manufactur',\n",
       " 'add',\n",
       " 'antioxid',\n",
       " 'dha',\n",
       " 'product',\n",
       " 'agre',\n",
       " 'great',\n",
       " 'question',\n",
       " 'may',\n",
       " 'question',\n",
       " 'manufactur',\n",
       " 'know',\n",
       " 'dha',\n",
       " 'oil',\n",
       " 'alga',\n",
       " 'appear',\n",
       " 'effect',\n",
       " 'studi',\n",
       " 'dha',\n",
       " 'vegan',\n",
       " 'supplement',\n",
       " 'provid',\n",
       " 'epa',\n",
       " 'dha',\n",
       " 'import',\n",
       " 'seen',\n",
       " 'vegan',\n",
       " 'dha',\n",
       " 'supplement',\n",
       " 'make',\n",
       " 'mention',\n",
       " 'product',\n",
       " 'contain',\n",
       " 'epa',\n",
       " 'fish',\n",
       " 'oil',\n",
       " 'clear',\n",
       " 'assum',\n",
       " 'miss',\n",
       " 'seen',\n",
       " 'quit',\n",
       " 'commerci',\n",
       " 'omega',\n",
       " 'pill',\n",
       " 'includ',\n",
       " 'dha',\n",
       " 'epa',\n",
       " 'one',\n",
       " 'exampl',\n",
       " 'one',\n",
       " 'promot',\n",
       " 'one',\n",
       " 'pop',\n",
       " 'random',\n",
       " 'search',\n",
       " 'http',\n",
       " 'sure',\n",
       " 'pill',\n",
       " 'dha',\n",
       " 'think',\n",
       " 'hard',\n",
       " 'find',\n",
       " 'one',\n",
       " 'epa',\n",
       " 'alga',\n",
       " 'provid',\n",
       " 'dha',\n",
       " 'epa',\n",
       " 'figur',\n",
       " 'alga',\n",
       " 'contain',\n",
       " 'dha',\n",
       " 'epa',\n",
       " 'fish',\n",
       " 'oil',\n",
       " 'contain',\n",
       " 'dha',\n",
       " 'epa',\n",
       " 'fish',\n",
       " 'eat',\n",
       " 'alga',\n",
       " 'vegan',\n",
       " 'compani',\n",
       " 'dha',\n",
       " 'assum',\n",
       " 'differ',\n",
       " 'differ',\n",
       " 'pill',\n",
       " 'claim',\n",
       " 'due',\n",
       " 'differ',\n",
       " 'process',\n",
       " 'techniqu',\n",
       " 'right',\n",
       " 'pill',\n",
       " 'claim',\n",
       " 'dha',\n",
       " 'simpli',\n",
       " 'report',\n",
       " 'epa',\n",
       " 'algal',\n",
       " 'dha',\n",
       " 'supplement',\n",
       " 'contain',\n",
       " 'dha',\n",
       " 'increasingli',\n",
       " 'though',\n",
       " 'product',\n",
       " 'dha',\n",
       " 'epa',\n",
       " 'type',\n",
       " 'vegan',\n",
       " 'omega',\n",
       " 'amazon',\n",
       " 'find',\n",
       " 'even',\n",
       " 'expens',\n",
       " 'algal',\n",
       " 'product',\n",
       " 'cours',\n",
       " 'good',\n",
       " 'take',\n",
       " 'dha',\n",
       " 'epa',\n",
       " 'essenti',\n",
       " 'dha',\n",
       " 'epa',\n",
       " 'bodi',\n",
       " 'dha',\n",
       " 'convert',\n",
       " 'epa',\n",
       " 'vice',\n",
       " 'find',\n",
       " 'thought',\n",
       " 'provok',\n",
       " 'fish',\n",
       " 'oil',\n",
       " 'compani',\n",
       " 'shift',\n",
       " 'balanc',\n",
       " 'dha',\n",
       " 'epa',\n",
       " 'supplement',\n",
       " 'contain',\n",
       " 'epa',\n",
       " 'dha',\n",
       " 'greater',\n",
       " 'amount',\n",
       " 'epa',\n",
       " 'dha',\n",
       " 'bodi',\n",
       " 'found',\n",
       " 'effect',\n",
       " 'mood',\n",
       " 'issu',\n",
       " 'well',\n",
       " 'feel',\n",
       " 'issu',\n",
       " 'well',\n",
       " 'vegan',\n",
       " 'may',\n",
       " 'compromis',\n",
       " 'take',\n",
       " 'dha',\n",
       " 'creat',\n",
       " 'level',\n",
       " 'dha',\n",
       " 'epa',\n",
       " 'advers',\n",
       " 'effect',\n",
       " 'research',\n",
       " 'articl',\n",
       " 'like',\n",
       " 'good',\n",
       " 'question',\n",
       " 'one',\n",
       " 'manufactur',\n",
       " 'like',\n",
       " 'studi',\n",
       " 'link',\n",
       " 'pubm',\n",
       " 'dietari',\n",
       " 'pattern',\n",
       " 'breast',\n",
       " 'cancer',\n",
       " 'risk',\n",
       " 'women',\n",
       " 'healthi',\n",
       " 'food',\n",
       " 'pattern',\n",
       " 'character',\n",
       " 'consumpt',\n",
       " 'veget',\n",
       " 'fruit',\n",
       " 'dairi',\n",
       " 'product',\n",
       " 'legum',\n",
       " 'oliv',\n",
       " 'veget',\n",
       " 'oil',\n",
       " 'fish',\n",
       " 'condiment',\n",
       " 'organ',\n",
       " 'meat',\n",
       " 'poultri',\n",
       " 'pickl',\n",
       " 'soya',\n",
       " 'grain',\n",
       " 'unhealthi',\n",
       " 'food',\n",
       " 'pattern',\n",
       " 'character',\n",
       " 'consumpt',\n",
       " 'soft',\n",
       " 'drink',\n",
       " 'sugar',\n",
       " 'tea',\n",
       " 'coffe',\n",
       " 'french',\n",
       " 'fri',\n",
       " 'potato',\n",
       " 'chip',\n",
       " 'salt',\n",
       " 'sweet',\n",
       " 'dessert',\n",
       " 'hydrogen',\n",
       " 'fat',\n",
       " 'nut',\n",
       " 'industri',\n",
       " 'juic',\n",
       " 'refin',\n",
       " 'grain',\n",
       " 'red',\n",
       " 'process',\n",
       " 'meat',\n",
       " 'healthi',\n",
       " 'food',\n",
       " 'pattern',\n",
       " 'includ',\n",
       " 'low',\n",
       " 'fat',\n",
       " 'dairi',\n",
       " 'oliv',\n",
       " 'veget',\n",
       " 'oil',\n",
       " 'organ',\n",
       " 'meat',\n",
       " 'poultri',\n",
       " 'exclud',\n",
       " 'tea',\n",
       " 'studi',\n",
       " 'exemplifi',\n",
       " 'import',\n",
       " 'abil',\n",
       " 'read',\n",
       " 'studi',\n",
       " 'understand',\n",
       " 'statist',\n",
       " 'method',\n",
       " 'order',\n",
       " 'interpret',\n",
       " 'studi',\n",
       " 'correctli',\n",
       " 'princip',\n",
       " 'compon',\n",
       " 'analysi',\n",
       " 'http',\n",
       " 'princip',\n",
       " 'compon',\n",
       " 'analysi',\n",
       " 'factor',\n",
       " 'analyt',\n",
       " 'techniqu',\n",
       " 'goal',\n",
       " 'dimens',\n",
       " 'reduct',\n",
       " 'prior',\n",
       " 'statist',\n",
       " 'analysi',\n",
       " 'direct',\n",
       " 'infer',\n",
       " 'healthi',\n",
       " 'pattern',\n",
       " 'fit',\n",
       " 'unhealthi',\n",
       " 'pattern',\n",
       " 'make',\n",
       " 'sens',\n",
       " 'model',\n",
       " 'pattern',\n",
       " 'simpli',\n",
       " 'neg',\n",
       " 'healthiest',\n",
       " 'pattern',\n",
       " 'one',\n",
       " 'correct',\n",
       " 'interpret',\n",
       " 'statist',\n",
       " 'found',\n",
       " 'two',\n",
       " 'orthogon',\n",
       " 'factor',\n",
       " 'vari',\n",
       " 'significantli',\n",
       " 'sampl',\n",
       " 'atyp',\n",
       " 'variat',\n",
       " 'consumpt',\n",
       " 'veget',\n",
       " 'fruit',\n",
       " 'dairi',\n",
       " 'increas',\n",
       " 'dietari',\n",
       " 'compon',\n",
       " 'decreas',\n",
       " 'variat',\n",
       " 'consumpt',\n",
       " 'soft',\n",
       " 'drink',\n",
       " 'sugar',\n",
       " 'tea',\n",
       " 'increas',\n",
       " 'dietari',\n",
       " 'compon',\n",
       " 'decreas',\n",
       " 'sampl',\n",
       " 'diet',\n",
       " 'ffq',\n",
       " 'vari',\n",
       " 'person',\n",
       " 'person',\n",
       " 'fair',\n",
       " 'studi',\n",
       " 'call',\n",
       " 'healthi',\n",
       " 'unhealthi',\n",
       " 'base',\n",
       " 'characterist',\n",
       " 'plausibl',\n",
       " 'call',\n",
       " 'tradit',\n",
       " 'rural',\n",
       " 'urban',\n",
       " 'industri',\n",
       " 'model',\n",
       " 'look',\n",
       " 'diet',\n",
       " 'independ',\n",
       " 'variabl',\n",
       " 'found',\n",
       " 'associ',\n",
       " 'higher',\n",
       " 'breast',\n",
       " 'cancer',\n",
       " 'risk',\n",
       " 'found',\n",
       " 'associ',\n",
       " 'lower',\n",
       " 'risk',\n",
       " 'way',\n",
       " 'vari',\n",
       " 'diet',\n",
       " 'protect',\n",
       " 'breast',\n",
       " 'cancer',\n",
       " 'reduc',\n",
       " 'b',\n",
       " 'increas',\n",
       " 'b',\n",
       " 'interpret',\n",
       " 'simpli',\n",
       " 'straightforward',\n",
       " 'list',\n",
       " 'healthi',\n",
       " 'unhealthi',\n",
       " 'thing',\n",
       " 'fact',\n",
       " 'obviou',\n",
       " 'reason',\n",
       " 'tea',\n",
       " 'consumpt',\n",
       " 'tend',\n",
       " 'increas',\n",
       " 'refin',\n",
       " 'process',\n",
       " 'food',\n",
       " 'tea',\n",
       " 'health',\n",
       " 'se',\n",
       " 'obviou',\n",
       " 'reason',\n",
       " 'organ',\n",
       " 'meat',\n",
       " 'common',\n",
       " 'peopl',\n",
       " 'greater',\n",
       " 'access',\n",
       " 'fresh',\n",
       " 'tradit',\n",
       " 'food',\n",
       " 'health',\n",
       " 'organ',\n",
       " 'meat',\n",
       " 'ask',\n",
       " 'studi',\n",
       " 'valuabl',\n",
       " 'pinpoint',\n",
       " 'good',\n",
       " 'bad',\n",
       " 'breast',\n",
       " 'cancer',\n",
       " 'reli',\n",
       " 'research',\n",
       " 'order',\n",
       " 'interpret',\n",
       " 'healthiest',\n",
       " 'dietari',\n",
       " 'pattern',\n",
       " 'prevent',\n",
       " 'breast',\n",
       " 'cancer',\n",
       " 'note',\n",
       " 'articl',\n",
       " 'studi',\n",
       " 'question',\n",
       " 'introduc',\n",
       " 'latest',\n",
       " 'greatest',\n",
       " 'respect',\n",
       " 'studi',\n",
       " 'dr',\n",
       " 'healthier',\n",
       " 'eat',\n",
       " 'associ',\n",
       " 'elimin',\n",
       " 'odd',\n",
       " 'breast',\n",
       " 'cancer',\n",
       " 'healthi',\n",
       " 'eat',\n",
       " 'associ',\n",
       " 'time',\n",
       " 'odd',\n",
       " 'healthier',\n",
       " 'eat',\n",
       " 'pattern',\n",
       " 'includ',\n",
       " 'veget',\n",
       " 'fruit',\n",
       " 'dairi',\n",
       " 'product',\n",
       " 'legum',\n",
       " 'oliv',\n",
       " 'veget',\n",
       " 'oil',\n",
       " 'fish',\n",
       " 'condiment',\n",
       " 'organ',\n",
       " 'meat',\n",
       " 'poultri',\n",
       " 'pickl',\n",
       " 'soya',\n",
       " 'matter',\n",
       " 'want',\n",
       " 'spin',\n",
       " 'use',\n",
       " 'good',\n",
       " 'doctor',\n",
       " 'post',\n",
       " 'link',\n",
       " 'entir',\n",
       " 'studi',\n",
       " 'studi',\n",
       " 'freeli',\n",
       " 'access',\n",
       " 'charl',\n",
       " 'reach',\n",
       " 'sourc',\n",
       " 'link',\n",
       " 'publish',\n",
       " 'pubm',\n",
       " 'citat',\n",
       " 'quot',\n",
       " 'result',\n",
       " 'tabl',\n",
       " 'model',\n",
       " 'ii',\n",
       " 'mention',\n",
       " 'call',\n",
       " 'model',\n",
       " 'univari',\n",
       " 'focu',\n",
       " 'one',\n",
       " 'pattern',\n",
       " 'time',\n",
       " 'independ',\n",
       " 'variabl',\n",
       " 'interest',\n",
       " 'statist',\n",
       " 'control',\n",
       " 'age',\n",
       " 'menopaus',\n",
       " 'statu',\n",
       " 'independ',\n",
       " 'variabl',\n",
       " 'note',\n",
       " 'qualiti',\n",
       " 'report',\n",
       " 'studi',\n",
       " 'either',\n",
       " 'op',\n",
       " 'talk',\n",
       " 'studi',\n",
       " 'assum',\n",
       " 'talk',\n",
       " 'studi',\n",
       " 'studi',\n",
       " 'tri',\n",
       " 'wrote',\n",
       " 'spin',\n",
       " 'back',\n",
       " 'assur',\n",
       " 'found',\n",
       " 'two',\n",
       " 'pattern',\n",
       " 'span',\n",
       " 'dietari',\n",
       " 'variat',\n",
       " 'popul',\n",
       " 'ask',\n",
       " 'healthi',\n",
       " 'pattern',\n",
       " 'actual',\n",
       " 'ask',\n",
       " 'front',\n",
       " 'pattern',\n",
       " 'variat',\n",
       " 'explain',\n",
       " 'greatest',\n",
       " 'variat',\n",
       " 'health',\n",
       " 'outcom',\n",
       " 'form',\n",
       " 'question',\n",
       " 'list',\n",
       " 'distinguish',\n",
       " 'appar',\n",
       " 'healthi',\n",
       " 'food',\n",
       " 'appar',\n",
       " 'unhealthi',\n",
       " 'former',\n",
       " 'studi',\n",
       " 'exemplifi',\n",
       " 'import',\n",
       " 'abil',\n",
       " 'read',\n",
       " 'studi',\n",
       " 'understand',\n",
       " 'statist',\n",
       " 'method',\n",
       " 'order',\n",
       " 'interpret',\n",
       " 'studi',\n",
       " 'correctli',\n",
       " 'princip',\n",
       " 'compon',\n",
       " 'analysi',\n",
       " 'http',\n",
       " 'princip',\n",
       " 'compon',\n",
       " 'analysi',\n",
       " 'factor',\n",
       " 'analyt',\n",
       " 'techniqu',\n",
       " 'goal',\n",
       " 'dimens',\n",
       " 'reduct',\n",
       " 'prior',\n",
       " 'statist',\n",
       " 'analysi',\n",
       " 'direct',\n",
       " 'infer',\n",
       " 'healthi',\n",
       " 'pattern',\n",
       " 'fit',\n",
       " 'unhealthi',\n",
       " 'pattern',\n",
       " 'make',\n",
       " 'sens',\n",
       " 'model',\n",
       " 'pattern',\n",
       " 'simpli',\n",
       " 'neg',\n",
       " ...]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_text['TEXT'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alkylphenol</th>\n",
       "      <th>human</th>\n",
       "      <th>milk</th>\n",
       "      <th>relat</th>\n",
       "      <th>dietari</th>\n",
       "      <th>habit</th>\n",
       "      <th>central</th>\n",
       "      <th>taiwan</th>\n",
       "      <th>pubm</th>\n",
       "      <th>ncbi</th>\n",
       "      <th>...</th>\n",
       "      <th>six-year</th>\n",
       "      <th>inchianti</th>\n",
       "      <th>tuscani</th>\n",
       "      <th>studies-depress</th>\n",
       "      <th>eurosav</th>\n",
       "      <th>self-inflict</th>\n",
       "      <th>eurostat</th>\n",
       "      <th>suicide-record</th>\n",
       "      <th>scarciti</th>\n",
       "      <th>trim-and-fil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 19930 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [alkylphenol, human, milk, relat, dietari, habit, central, taiwan, pubm, ncbi, abstract, aim, studi, determin, concentr, num, nonylphenol, np, octylphenol, op, sampl, examin, factor, includ, mother, demograph, women, consum, median, amount, cook, oil, significantli, higher, ng/g, consumpt, beta, fish, capsul, adjust, age, bodi, mass, index, bmi, process, product, food, pattern, meat, analysi, strongli, aid, suggest, nurs, order, protect, infant, np/op, exposur, elsevi, right, reserv, phosphat, vascular, toxin, elev, level, advanc, renal, failur, dysregul, calcium, parathyroid, hormon, vitamin, contribut, complex, chronic, kidney, disease-miner, bone, diseas, ckd-mbd, converg, evid, vitro, clinic, epidemiolog, increas, calcif, mortal, vessel, expos, high, condit, develop, apoptosi, convert, bone-lik, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 19930 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_queries = tf_idf_matrix[0:0]\n",
    "tf_idf_queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(queries_text)):\n",
    "    tf_idf_queries = tf_idf_queries.append(pd.Series(0, index=tf_idf_queries.columns), ignore_index=True)\n",
    "    for token in queries_text['TEXT'][i]:\n",
    "        for col in tf_idf_queries.columns:\n",
    "            if token == col:\n",
    "                tf_idf_queries[col][i] = tf_idf_queries[col][i] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alkylphenol</th>\n",
       "      <th>human</th>\n",
       "      <th>milk</th>\n",
       "      <th>relat</th>\n",
       "      <th>dietari</th>\n",
       "      <th>habit</th>\n",
       "      <th>central</th>\n",
       "      <th>taiwan</th>\n",
       "      <th>pubm</th>\n",
       "      <th>ncbi</th>\n",
       "      <th>...</th>\n",
       "      <th>six-year</th>\n",
       "      <th>inchianti</th>\n",
       "      <th>tuscani</th>\n",
       "      <th>studies-depress</th>\n",
       "      <th>eurosav</th>\n",
       "      <th>self-inflict</th>\n",
       "      <th>eurostat</th>\n",
       "      <th>suicide-record</th>\n",
       "      <th>scarciti</th>\n",
       "      <th>trim-and-fil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 19930 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   alkylphenol  human  milk  relat  dietari  habit  central  taiwan  pubm  \\\n",
       "0          0.0    1.0   0.0    0.0     11.0    0.0      0.0     0.0   2.0   \n",
       "1          0.0    0.0   1.0    0.0      0.0    0.0      0.0     0.0   0.0   \n",
       "2          0.0    5.0   2.0    4.0      6.0    0.0      1.0     0.0   2.0   \n",
       "3          0.0    0.0   0.0    0.0      0.0    0.0      0.0     0.0   0.0   \n",
       "4          0.0    0.0   0.0    0.0      1.0    0.0      0.0     0.0   0.0   \n",
       "\n",
       "   ncbi  ...  six-year  inchianti  tuscani  studies-depress  eurosav  \\\n",
       "0   0.0  ...       0.0        0.0      0.0              0.0      0.0   \n",
       "1   0.0  ...       0.0        0.0      0.0              0.0      0.0   \n",
       "2   0.0  ...       0.0        0.0      0.0              0.0      0.0   \n",
       "3   0.0  ...       0.0        0.0      0.0              0.0      0.0   \n",
       "4   0.0  ...       0.0        0.0      0.0              0.0      0.0   \n",
       "\n",
       "   self-inflict  eurostat  suicide-record  scarciti  trim-and-fil  \n",
       "0           0.0       0.0             0.0       0.0           0.0  \n",
       "1           0.0       0.0             0.0       0.0           0.0  \n",
       "2           0.0       0.0             0.0       0.0           0.0  \n",
       "3           0.0       0.0             0.0       0.0           0.0  \n",
       "4           0.0       0.0             0.0       0.0           0.0  \n",
       "\n",
       "[5 rows x 19930 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_queries.head()\n",
    "tf_idf_queries = tf_idf_queries.astype('float32')\n",
    "tf_idf_queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_query(textstring):\n",
    "    if type(textstring) == str:\n",
    "        tokenized_query = textstring.split()\n",
    "    else:\n",
    "        tokenized_query = textstring\n",
    "        \n",
    "    df_query = tf_idf_matrix[0:0] #dataframe of tf-idf weights of a query\n",
    "    df_query = df_query.append(pd.Series(0, index=df_query.columns), ignore_index=True)\n",
    "    for token in tokenized_query:\n",
    "        for col in df_query.columns:\n",
    "            if token == col:\n",
    "                df_query[col][0] = df_query[col][0] + 1 #raw term frequency\n",
    "    \n",
    "    df_query = df_query.replace(0, np.nan)\n",
    "    \n",
    "    df_query = np.log(df_query) + 1 #log term freq(as in the slides)\n",
    "    \n",
    "    df_query = df_query.fillna(0)\n",
    "    \n",
    "    for col in df_query.columns:\n",
    "        df_query[col][0] = df_query[col][0] * idf[col]\n",
    "        \n",
    "    return df_query\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_with_preclustering(string_query, k = 5, IDs_of_retrieved_docs = False):\n",
    "    vector_q = vectorize_query(string_query)\n",
    "    return ir_preclustering(vector_q.iloc[0], K = k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>MED-2423</td>\n",
       "      <td>dietari pattern breast cancer risk women pubm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>MED-1363</td>\n",
       "      <td>toward healthier mediterranean diet pubm ncbi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>MED-1196</td>\n",
       "      <td>dietari pattern depress symptom middl age abst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>MED-1955</td>\n",
       "      <td>matern dietari pattern preterm deliveri result...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>MED-2209</td>\n",
       "      <td>relationship process method glycem indic ten s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>MED-2511</td>\n",
       "      <td>okinawan diet health implic low-calori nutrien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1419</th>\n",
       "      <td>MED-2852</td>\n",
       "      <td>prospect studi dietari pattern meat intak risk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2746</th>\n",
       "      <td>MED-4765</td>\n",
       "      <td>dietari predictor num year waist circumfer pub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>MED-2202</td>\n",
       "      <td>sweet potato review past present futur role hu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>MED-2421</td>\n",
       "      <td>birth weight head circumfer prenat exposur acr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                                               TEXT\n",
       "1142  MED-2423  dietari pattern breast cancer risk women pubm ...\n",
       "303   MED-1363  toward healthier mediterranean diet pubm ncbi ...\n",
       "169   MED-1196  dietari pattern depress symptom middl age abst...\n",
       "755   MED-1955  matern dietari pattern preterm deliveri result...\n",
       "966   MED-2209  relationship process method glycem indic ten s...\n",
       "1200  MED-2511  okinawan diet health implic low-calori nutrien...\n",
       "1419  MED-2852  prospect studi dietari pattern meat intak risk...\n",
       "2746  MED-4765  dietari predictor num year waist circumfer pub...\n",
       "959   MED-2202  sweet potato review past present futur role hu...\n",
       "1140  MED-2421  birth weight head circumfer prenat exposur acr..."
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_with_preclustering(queries_text['TEXT'][0], k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find all relevant documents for the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_relevant_docs(string_query):\n",
    "    query_row = (queries_text.loc[queries_text['TEXT'].isin([string_query])])\n",
    "    query_id = query_row.iloc[0][\"ID\"]\n",
    "    relevance_lvl = [1, 2]\n",
    "    return queries_relevance.loc[queries_relevance['QUERY_ID'].isin([query_id]) & queries_relevance['RELEVANCE_LEVEL'].isin(relevance_lvl)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QUERY_ID</th>\n",
       "      <th>0</th>\n",
       "      <th>DOC_ID</th>\n",
       "      <th>RELEVANCE_LEVEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-2421</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-2422</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-2416</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-2423</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-2417</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-2418</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-4451</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-2420</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-2414</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-4070</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-3498</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-2424</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-2426</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-2674</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-2675</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-2676</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-2677</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-2678</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-2679</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-4037</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-4038</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-4976</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-4450</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-5085</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-5086</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-5087</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-5088</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-5089</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-5322</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-5323</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-5324</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-5325</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-5326</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-5327</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-5328</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-5329</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-5330</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-5331</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-5332</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-5333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-5334</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-5335</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-5363</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-5337</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-5338</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-5339</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-5340</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-5341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-5342</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   QUERY_ID  0    DOC_ID  RELEVANCE_LEVEL\n",
       "0   PLAIN-1  0  MED-2421                2\n",
       "1   PLAIN-1  0  MED-2422                2\n",
       "2   PLAIN-1  0  MED-2416                2\n",
       "3   PLAIN-1  0  MED-2423                2\n",
       "4   PLAIN-1  0  MED-2417                2\n",
       "5   PLAIN-1  0  MED-2418                2\n",
       "6   PLAIN-1  0  MED-4451                2\n",
       "7   PLAIN-1  0  MED-2420                2\n",
       "8   PLAIN-1  0  MED-2414                1\n",
       "9   PLAIN-1  0  MED-4070                1\n",
       "10  PLAIN-1  0  MED-3498                1\n",
       "11  PLAIN-1  0  MED-2424                1\n",
       "12  PLAIN-1  0  MED-2426                1\n",
       "13  PLAIN-1  0  MED-2674                1\n",
       "14  PLAIN-1  0  MED-2675                1\n",
       "15  PLAIN-1  0  MED-2676                1\n",
       "16  PLAIN-1  0  MED-2677                1\n",
       "17  PLAIN-1  0  MED-2678                1\n",
       "18  PLAIN-1  0  MED-2679                1\n",
       "19  PLAIN-1  0  MED-4037                1\n",
       "20  PLAIN-1  0  MED-4038                1\n",
       "21  PLAIN-1  0  MED-4976                1\n",
       "22  PLAIN-1  0  MED-4450                1\n",
       "23  PLAIN-1  0  MED-5085                1\n",
       "24  PLAIN-1  0  MED-5086                1\n",
       "25  PLAIN-1  0  MED-5087                1\n",
       "26  PLAIN-1  0  MED-5088                1\n",
       "27  PLAIN-1  0  MED-5089                1\n",
       "28  PLAIN-1  0  MED-5322                1\n",
       "29  PLAIN-1  0  MED-5323                1\n",
       "30  PLAIN-1  0  MED-5324                1\n",
       "31  PLAIN-1  0  MED-5325                1\n",
       "32  PLAIN-1  0  MED-5326                1\n",
       "33  PLAIN-1  0  MED-5327                1\n",
       "34  PLAIN-1  0  MED-5328                1\n",
       "35  PLAIN-1  0  MED-5329                1\n",
       "36  PLAIN-1  0  MED-5330                1\n",
       "37  PLAIN-1  0  MED-5331                1\n",
       "38  PLAIN-1  0  MED-5332                1\n",
       "39  PLAIN-1  0  MED-5333                1\n",
       "40  PLAIN-1  0  MED-5334                1\n",
       "41  PLAIN-1  0  MED-5335                1\n",
       "42  PLAIN-1  0  MED-5363                1\n",
       "43  PLAIN-1  0  MED-5337                1\n",
       "44  PLAIN-1  0  MED-5338                1\n",
       "45  PLAIN-1  0  MED-5339                1\n",
       "46  PLAIN-1  0  MED-5340                1\n",
       "47  PLAIN-1  0  MED-5341                1\n",
       "48  PLAIN-1  0  MED-5342                1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_relevant_docs(queries_text['TEXT'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate performance by:\n",
    " Precision\n",
    " MAP \n",
    " nDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(actual, predicted):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), len(predicted))\n",
    "\n",
    "def mapk(actual, predicted, k=5):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k.\n",
    "    This function computes the mean average prescision at k between two lists\n",
    "    of lists of items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of lists of elements that are to be predicted \n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg(element_list):\n",
    "    \"\"\"\n",
    "    Discounted Cumulative Gain (DCG)\n",
    "    Parameters:\n",
    "        element_list - a list of ranks Ex: [5,4,2,2,1]\n",
    "    Returns:\n",
    "        score\n",
    "    \"\"\"\n",
    "    score = 0.0\n",
    "    for order, rank in enumerate(element_list):\n",
    "        score += float(rank)/math.log((order+2))\n",
    "    return score\n",
    "\n",
    "\n",
    "def ndcg(reference, hypothesis):\n",
    "    \"\"\"\n",
    "    Normalized Discounted Cumulative Gain (nDCG)\n",
    "    Normalized version of DCG:\n",
    "        nDCG = DCG(hypothesis)/DCG(reference)\n",
    "    Parameters:\n",
    "        reference   - a gold standard (perfect) ordering Ex: [5,4,3,2,1]\n",
    "        hypothesis  - a proposed ordering Ex: [5,2,2,3,1]\n",
    "    Returns:\n",
    "        ndcg_score  - normalized score\n",
    "    \"\"\"\n",
    "    if dcg(reference) == 0:\n",
    "        return 0 \n",
    "    else:\n",
    "        return dcg(hypothesis)/dcg(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_retrieve_with_preclustering(query_text):\n",
    "    ## returns the triple (Precision, Average Precision, Normalized Discounted Cumulative Gain)\n",
    "    \n",
    "    retrieved_df = retrieve_with_preclustering(query_text)\n",
    "    ids_retrieved = []\n",
    "    for i in range(len(retrieved_df)):\n",
    "        ids_retrieved.append(retrieved_df.iloc[i].ID)\n",
    "    ids_retrieved.sort()\n",
    "    \n",
    "    relevant = true_relevant_docs(query_text)\n",
    "    ids_true_relevant = []\n",
    "    for i in range(len(relevant)):\n",
    "        ids_true_relevant.append(relevant.iloc[i].DOC_ID)\n",
    "    ids_true_relevant.sort()\n",
    "    \n",
    "    #count true positives and false positives\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    for i in ids_retrieved:\n",
    "        for j in ids_true_relevant:\n",
    "            if i == j:\n",
    "                tp += 1 \n",
    "                break\n",
    "            else:\n",
    "                if i < j:\n",
    "                    fp += 1 \n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "    if (tp == 0) & (fp == 0):\n",
    "        precision = 0\n",
    "    else:\n",
    "        precision = tp/(tp+fp)\n",
    "    #cannot calculate recall, since we predefined the number of retrieved documents => apriori algorithm cannot retrieve all documents\n",
    "    \n",
    "    #then calculate Average precision across retrieved documents\n",
    "    ap = apk(ids_true_relevant, ids_retrieved)\n",
    "    \n",
    "    #since we have graded relevance annotations, we can also calculate Normalized Discounted Cumulative Gain\n",
    "    list_of_ranks_of_retrieved_docs = []\n",
    "    for i in ids_retrieved:\n",
    "        if i in ids_true_relevant:\n",
    "            list_of_ranks_of_retrieved_docs.append(relevant.loc[relevant['DOC_ID'].isin([i])].RELEVANCE_LEVEL.iloc[0])\n",
    "        else:\n",
    "            list_of_ranks_of_retrieved_docs.append(0)\n",
    "\n",
    "                                               \n",
    "    list_of_ranks_of_relevant_docs = []\n",
    "    for i in ids_true_relevant:\n",
    "        list_of_ranks_of_relevant_docs.append(relevant.loc[relevant['DOC_ID'].isin([i])].RELEVANCE_LEVEL.iloc[0])\n",
    "    list_of_ranks_of_relevant_docs.sort(reverse = True)\n",
    "    \n",
    "    k=len(list_of_ranks_of_retrieved_docs)\n",
    "    list_of_ranks_of_relevant_docs = list_of_ranks_of_relevant_docs[:k]\n",
    "        \n",
    "    return precision, ap, ndcg(list_of_ranks_of_relevant_docs, list_of_ranks_of_retrieved_docs)       \n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_preclustering():\n",
    "    evaluation = queries_text.copy()\n",
    "    evaluation.insert(2, \"Precision\", 0)\n",
    "    evaluation.insert(3, \"Average Precision\", 0)\n",
    "    evaluation.insert(4, \"nDCG\", 0)\n",
    "    \n",
    "    for i in range(len(evaluation)):\n",
    "\n",
    "        p, a, n = evaluate_retrieve_with_preclustering(queries_text.loc[i, 'TEXT'])\n",
    "        evaluation.loc[i, 'Precision'] = p\n",
    "        evaluation.loc[i, 'Average Precision'] = a\n",
    "        evaluation.loc[i, 'nDCG'] = n\n",
    "    \n",
    "    print('Average precision across all queries = ' + str(evaluation['Precision'].mean()))\n",
    "    print('Mean Average Precision = ' + str(evaluation['Average Precision'].mean()))\n",
    "    print('Average nDCG = ' + str(evaluation['nDCG'].mean()))\n",
    "    \n",
    "    return evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision across all queries = 0.18907692307692314\n",
      "Mean Average Precision = 0.11784957264957267\n",
      "Average nDCG = 0.15597203856880254\n"
     ]
    }
   ],
   "source": [
    "evaluate_with_leaders_state_11 = evaluate_preclustering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Average Precision</th>\n",
       "      <th>nDCG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>[deep, fri, food, may, caus, cancer, latest, s...</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.131205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PLAIN-1007</td>\n",
       "      <td>[ddt, persist, organ, pollut, industri, toxin,...</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.277273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PLAIN-101</td>\n",
       "      <td>[treat, multipl, sclerosi, diet, multipl, scle...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PLAIN-1017</td>\n",
       "      <td>[detoxif, cancer, raw, food, heart, health, he...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PLAIN-1027</td>\n",
       "      <td>[dietari, guidelin, heart, diseas, cardiovascu...</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.360055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PLAIN-1038</td>\n",
       "      <td>[dog, meat, anim, product, cat, heart, health,...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PLAIN-1049</td>\n",
       "      <td>[dr, heart, health, heart, diseas, egg, choles...</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.181542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PLAIN-1065</td>\n",
       "      <td>[dr, walter, mortal, heart, diseas, heart, hea...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PLAIN-1077</td>\n",
       "      <td>[thyroid, health, hijiki, sushi, iodin, sea, v...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.699215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PLAIN-1087</td>\n",
       "      <td>[easter, island, mortal, muscl, strength, morb...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                                               TEXT  Precision  \\\n",
       "0     PLAIN-1  [deep, fri, food, may, caus, cancer, latest, s...       0.20   \n",
       "1  PLAIN-1007  [ddt, persist, organ, pollut, industri, toxin,...       0.40   \n",
       "2   PLAIN-101  [treat, multipl, sclerosi, diet, multipl, scle...       0.00   \n",
       "3  PLAIN-1017  [detoxif, cancer, raw, food, heart, health, he...       0.00   \n",
       "4  PLAIN-1027  [dietari, guidelin, heart, diseas, cardiovascu...       0.40   \n",
       "5  PLAIN-1038  [dog, meat, anim, product, cat, heart, health,...       0.00   \n",
       "6  PLAIN-1049  [dr, heart, health, heart, diseas, egg, choles...       0.20   \n",
       "7  PLAIN-1065  [dr, walter, mortal, heart, diseas, heart, hea...       0.00   \n",
       "8  PLAIN-1077  [thyroid, health, hijiki, sushi, iodin, sea, v...       0.75   \n",
       "9  PLAIN-1087  [easter, island, mortal, muscl, strength, morb...       0.00   \n",
       "\n",
       "   Average Precision      nDCG  \n",
       "0           0.040000  0.131205  \n",
       "1           0.130000  0.277273  \n",
       "2           0.000000  0.000000  \n",
       "3           0.000000  0.000000  \n",
       "4           0.200000  0.360055  \n",
       "5           0.000000  0.000000  \n",
       "6           0.066667  0.181542  \n",
       "7           0.000000  0.000000  \n",
       "8           0.550000  0.699215  \n",
       "9           0.000000  0.000000  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_with_leaders_state_11.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Average Precision</th>\n",
       "      <th>nDCG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>325.000000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>325.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.189077</td>\n",
       "      <td>0.117850</td>\n",
       "      <td>0.155972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.286094</td>\n",
       "      <td>0.232718</td>\n",
       "      <td>0.252240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.213986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Precision  Average Precision        nDCG\n",
       "count  325.000000         325.000000  325.000000\n",
       "mean     0.189077           0.117850    0.155972\n",
       "std      0.286094           0.232718    0.252240\n",
       "min      0.000000           0.000000    0.000000\n",
       "25%      0.000000           0.000000    0.000000\n",
       "50%      0.000000           0.000000    0.000000\n",
       "75%      0.250000           0.100000    0.213986\n",
       "max      1.000000           1.000000    1.000000"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_with_leaders_state_11.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_with_leaders_state_110 = evaluate_preclustering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_with_leaders_state_110.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_with_leaders_state_110.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_with_leaders_state_1100 = evaluate_preclustering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_with_leaders_state_1100.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_with_leaders_state_1100.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_with_preclustering_faiss(string_query, k = 5, IDs_of_retrieved_docs = False):\n",
    "    vector_q = vectorize_query(string_query)\n",
    "    return ir_preclustering_faiss(vector_q.iloc[0].astype('float32'), K = k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_retrieve_with_preclustering_faiss(query_text):\n",
    "    ## returns the triple (Precision, Average Precision, Normalized Discounted Cumulative Gain)\n",
    "    \n",
    "    retrieved_df = retrieve_with_preclustering_faiss(query_text)\n",
    "    ids_retrieved = []\n",
    "    \n",
    "    for i in range(len(retrieved_df)):\n",
    "        ids_retrieved.append(retrieved_df.iloc[i]['ID'])\n",
    "    ids_retrieved.sort()\n",
    "    \n",
    "    relevant = true_relevant_docs(query_text)\n",
    "    ids_true_relevant = []\n",
    "    for i in range(len(relevant)):\n",
    "        ids_true_relevant.append(relevant.iloc[i].DOC_ID)\n",
    "    ids_true_relevant.sort()\n",
    "    \n",
    "    #count true positives and false positives\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    for i in ids_retrieved:\n",
    "        for j in ids_true_relevant:\n",
    "            if i == j:\n",
    "                tp += 1 \n",
    "                break\n",
    "            else:\n",
    "                if i < j:\n",
    "                    fp += 1 \n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "    if (tp == 0) & (fp == 0):\n",
    "        precision = 0\n",
    "    else:\n",
    "        precision = tp/(tp+fp)\n",
    "    #cannot calculate recall, since we predefined the number of retrieved documents => apriori algorithm cannot retrieve all documents\n",
    "    \n",
    "    #then calculate Average precision across retrieved documents\n",
    "    ap = apk(ids_true_relevant, ids_retrieved)\n",
    "    \n",
    "    #since we have graded relevance annotations, we can also calculate Normalized Discounted Cumulative Gain\n",
    "    list_of_ranks_of_retrieved_docs = []\n",
    "    for i in ids_retrieved:\n",
    "        if i in ids_true_relevant:\n",
    "            list_of_ranks_of_retrieved_docs.append(relevant.loc[relevant['DOC_ID'].isin([i])].RELEVANCE_LEVEL.iloc[0])\n",
    "        else:\n",
    "            list_of_ranks_of_retrieved_docs.append(0)\n",
    "\n",
    "                                               \n",
    "    list_of_ranks_of_relevant_docs = []\n",
    "    for i in ids_true_relevant:\n",
    "        list_of_ranks_of_relevant_docs.append(relevant.loc[relevant['DOC_ID'].isin([i])].RELEVANCE_LEVEL.iloc[0])\n",
    "    list_of_ranks_of_relevant_docs.sort(reverse = True)\n",
    "    \n",
    "    k=len(list_of_ranks_of_retrieved_docs)\n",
    "    list_of_ranks_of_relevant_docs = list_of_ranks_of_relevant_docs[:k]\n",
    "        \n",
    "    return precision, ap, ndcg(list_of_ranks_of_relevant_docs, list_of_ranks_of_retrieved_docs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_preclustering_faiss():\n",
    "    evaluation = queries_text.copy()\n",
    "    evaluation.insert(2, \"Precision\", 0)\n",
    "    evaluation.insert(3, \"Average Precision\", 0)\n",
    "    evaluation.insert(4, \"nDCG\", 0)\n",
    "    \n",
    "    for i in range(len(evaluation)):\n",
    "\n",
    "        p, a, n = evaluate_retrieve_with_preclustering_faiss(queries_text.loc[i, 'TEXT'])\n",
    "        evaluation.loc[i, 'Precision'] = p\n",
    "        evaluation.loc[i, 'Average Precision'] = a\n",
    "        evaluation.loc[i, 'nDCG'] = n\n",
    "    \n",
    "    print('Average precision across all queries = ' + str(evaluation['Precision'].mean()))\n",
    "    print('Mean Average Precision = ' + str(evaluation['Average Precision'].mean()))\n",
    "    print('Average nDCG = ' + str(evaluation['nDCG'].mean()))\n",
    "    \n",
    "    return evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_with_leaders_state_11_faiss = evaluate_preclustering_faiss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_with_leaders_state_11_faiss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_with_leaders_state_11_faiss.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_with_leaders_state_110_faiss = evaluate_preclustering_faiss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_with_leaders_state_110_faiss.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_with_leaders_state_110_faiss.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_with_leaders_state_1100_faiss = evaluate_preclustering_faiss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_with_leaders_state_1100_faiss.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_with_leaders_state_1100_faiss.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_retrieve_with_preclustering_kmeans(query_text):\n",
    "    ## returns the triple (Precision, Average Precision, Normalized Discounted Cumulative Gain)\n",
    "    \n",
    "    retrieved_df = retrieve_with_preclustering_kmeans(query_text)\n",
    "    ids_retrieved = []\n",
    "    for i in range(len(retrieved_df)):\n",
    "        ids_retrieved.append(retrieved_df.iloc[i].ID)\n",
    "    ids_retrieved.sort()\n",
    "    \n",
    "    relevant = true_relevant_docs(query_text)\n",
    "    ids_true_relevant = []\n",
    "    for i in range(len(relevant)):\n",
    "        ids_true_relevant.append(relevant.iloc[i].DOC_ID)\n",
    "    ids_true_relevant.sort()\n",
    "    \n",
    "    #count true positives and false positives\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    for i in ids_retrieved:\n",
    "        for j in ids_true_relevant:\n",
    "            if i == j:\n",
    "                tp += 1 \n",
    "                break\n",
    "            else:\n",
    "                if i < j:\n",
    "                    fp += 1 \n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "    if (tp == 0) & (fp == 0):\n",
    "        precision = 0\n",
    "    else:\n",
    "        precision = tp/(tp+fp)\n",
    "    #cannot calculate recall, since we predefined the number of retrieved documents => apriori algorithm cannot retrieve all documents\n",
    "    \n",
    "    #then calculate Average precision across retrieved documents\n",
    "    ap = apk(ids_true_relevant, ids_retrieved)\n",
    "    \n",
    "    #since we have graded relevance annotations, we can also calculate Normalized Discounted Cumulative Gain\n",
    "    list_of_ranks_of_retrieved_docs = []\n",
    "    for i in ids_retrieved:\n",
    "        if i in ids_true_relevant:\n",
    "            list_of_ranks_of_retrieved_docs.append(relevant.loc[relevant['DOC_ID'].isin([i])].RELEVANCE_LEVEL.iloc[0])\n",
    "        else:\n",
    "            list_of_ranks_of_retrieved_docs.append(0)\n",
    "\n",
    "                                               \n",
    "    list_of_ranks_of_relevant_docs = []\n",
    "    for i in ids_true_relevant:\n",
    "        list_of_ranks_of_relevant_docs.append(relevant.loc[relevant['DOC_ID'].isin([i])].RELEVANCE_LEVEL.iloc[0])\n",
    "    list_of_ranks_of_relevant_docs.sort(reverse = True)\n",
    "    \n",
    "    k=len(list_of_ranks_of_retrieved_docs)\n",
    "    list_of_ranks_of_relevant_docs = list_of_ranks_of_relevant_docs[:k]\n",
    "        \n",
    "    return precision, ap, ndcg(list_of_ranks_of_relevant_docs, list_of_ranks_of_retrieved_docs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_preclustering_kmeans():\n",
    "    evaluation = queries_text.copy()\n",
    "    evaluation.insert(2, \"Precision\", 0)\n",
    "    evaluation.insert(3, \"Average Precision\", 0)\n",
    "    evaluation.insert(4, \"nDCG\", 0)\n",
    "    \n",
    "    for i in range(len(evaluation)):\n",
    "\n",
    "        p, a, n = evaluate_retrieve_with_preclustering_kmeans(queries_text.loc[i, 'TEXT'])\n",
    "        evaluation.loc[i, 'Precision'] = p\n",
    "        evaluation.loc[i, 'Average Precision'] = a\n",
    "        evaluation.loc[i, 'nDCG'] = n\n",
    "    \n",
    "    print('Average precision across all queries = ' + str(evaluation['Precision'].mean()))\n",
    "    print('Mean Average Precision = ' + str(evaluation['Average Precision'].mean()))\n",
    "    print('Average nDCG = ' + str(evaluation['nDCG'].mean()))\n",
    "    \n",
    "    return evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
