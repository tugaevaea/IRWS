{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss                   # make faiss available\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import scipy.sparse as sp\n",
    "import collections\n",
    "import math\n",
    "import copy\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic 4: Efficient Vector Space Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MED-118</td>\n",
       "      <td>alkylphenols human milk relations dietary habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MED-329</td>\n",
       "      <td>phosphate vascular toxin pubmed ncbi abstract ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MED-330</td>\n",
       "      <td>dietary phosphorus acutely impairs endothelial...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MED-332</td>\n",
       "      <td>public health impact dietary phosphorus excess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MED-334</td>\n",
       "      <td>differences total vitro digestible phosphorus ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                               TEXT\n",
       "0  MED-118  alkylphenols human milk relations dietary habi...\n",
       "1  MED-329  phosphate vascular toxin pubmed ncbi abstract ...\n",
       "2  MED-330  dietary phosphorus acutely impairs endothelial...\n",
       "3  MED-332  public health impact dietary phosphorus excess...\n",
       "4  MED-334  differences total vitro digestible phosphorus ..."
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.read_csv('nfcorpus/dev.docs', sep='\\t', names=['ID', 'TEXT'])\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create token list out of document\n",
    "def tokenize(string):\n",
    "    return string.split()\n",
    "\n",
    "# apply term frequencies for each a single string (document)\n",
    "def tf(string): \n",
    "    # create bag of words from the string\n",
    "    bow = tokenize(string)\n",
    "    \n",
    "    tf_dict = {}\n",
    "    for word in bow:\n",
    "        if word in tf_dict:\n",
    "            tf_dict[word] += 1\n",
    "        else:\n",
    "            tf_dict[word] = 1\n",
    "            \n",
    "    for word in tf_dict:\n",
    "        tf_dict[word] = 1 + math.log(tf_dict[word])\n",
    "    \n",
    "    return tf_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We then call our function on every doc and store all these tf dictionaries. \n",
    "tf_dict = {}\n",
    "for index, row in corpus.iterrows():\n",
    "    doc_dict = tf(row['TEXT'])\n",
    "    tf_dict[index] = doc_dict\n",
    "\n",
    "# test if tfDict was created correctly\n",
    "tf_dict[0][\"alkylphenols\"]\n",
    "# alkylphenols for doc 0 : 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3193\n"
     ]
    }
   ],
   "source": [
    "# total number of documents in corpus\n",
    "no_of_docs = len(corpus.index)\n",
    "print(no_of_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# term - key, number of docs term occured in\n",
    "def count_occurances():\n",
    "    count_dict = {}\n",
    "    for key in tf_dict:\n",
    "        for key in tf_dict[key]:\n",
    "            if key in count_dict:\n",
    "                count_dict[key] += 1\n",
    "            else:\n",
    "                count_dict[key] = 1\n",
    "    return count_dict\n",
    "\n",
    "# test if count_occurances works\n",
    "count_oc = count_occurances()\n",
    "count_oc[\"alkylphenols\"] # checked with Elina, good\n",
    "\n",
    "# number of alkylphenols occurence in entire corpus = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.122806043659469"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# having total number of documents and number of occurances of each word in entire corpus we can calculate \n",
    "# idf for each term as log(total # of documents / # of documents with term in it)\n",
    "\n",
    "# idf is calculated per each term, thus we create dictionary with term as a key and idf as a value\n",
    "def idf():\n",
    "    \n",
    "    idf_dict = {}\n",
    "    for key in count_oc:\n",
    "        idf_dict[key] = math.log(no_of_docs/count_oc[key])\n",
    "    return idf_dict\n",
    "\n",
    "idf = idf()\n",
    "\n",
    "# test if idf function works\n",
    "idf[\"alkylphenols\"]\n",
    "\n",
    "# alkylphenols idf = 6.122806043659469"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result from def:\n",
      "6.122806043659469\n",
      "Manual result:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.122806043659469"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cosntructing the final tf-idf dictionary; tf-idf is calculated as tf-idf(t, d) = tf(t, d) * idf(t)\n",
    "# so for each key in tf dict we have to miltiply it with corresponsinf idf value\n",
    "\n",
    "def tf_idf():\n",
    "    d = copy.deepcopy(tf_dict)\n",
    "    for doc, value in d.items():\n",
    "        for word, value in d[doc].items():\n",
    "            d[doc][word] = value * idf[word]\n",
    "    return d\n",
    "\n",
    "# test if tf_idf works\n",
    "a = tf_idf()\n",
    "print('Result from def:')\n",
    "print(a[0][\"alkylphenols\"])\n",
    "\n",
    "# excpected result for (term, doc) --> (alkylphenols, 0) =  0.008547008547008548 * 6.122806043659469 = 0.05\n",
    "print('Manual result:')\n",
    "idf[\"alkylphenols\"] * tf_dict[0][\"alkylphenols\"]\n",
    "\n",
    "# it works :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alkylphenols</th>\n",
       "      <th>human</th>\n",
       "      <th>milk</th>\n",
       "      <th>relations</th>\n",
       "      <th>dietary</th>\n",
       "      <th>habits</th>\n",
       "      <th>central</th>\n",
       "      <th>taiwan</th>\n",
       "      <th>pubmed</th>\n",
       "      <th>ncbi</th>\n",
       "      <th>...</th>\n",
       "      <th>tuscany</th>\n",
       "      <th>studies-depression</th>\n",
       "      <th>suicides</th>\n",
       "      <th>eurosave</th>\n",
       "      <th>self-inflicted</th>\n",
       "      <th>eurostat</th>\n",
       "      <th>upward</th>\n",
       "      <th>suicide-recording</th>\n",
       "      <th>scarcity</th>\n",
       "      <th>trim-and-fill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.122806</td>\n",
       "      <td>3.386148</td>\n",
       "      <td>6.547579</td>\n",
       "      <td>5.429659</td>\n",
       "      <td>2.097678</td>\n",
       "      <td>6.023975</td>\n",
       "      <td>3.504368</td>\n",
       "      <td>5.503767</td>\n",
       "      <td>0.266507</td>\n",
       "      <td>0.27307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266507</td>\n",
       "      <td>0.27307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.600018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.600018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266507</td>\n",
       "      <td>0.27307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266507</td>\n",
       "      <td>0.27307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26951 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   alkylphenols     human      milk  relations   dietary    habits   central  \\\n",
       "0      6.122806  3.386148  6.547579   5.429659  2.097678  6.023975  3.504368   \n",
       "1      0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  0.000000   \n",
       "2      0.000000  0.000000  0.000000   0.000000  2.600018  0.000000  0.000000   \n",
       "3      0.000000  0.000000  0.000000   0.000000  2.600018  0.000000  0.000000   \n",
       "4      0.000000  0.000000  0.000000   0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "     taiwan    pubmed     ncbi  ...  tuscany  studies-depression  suicides  \\\n",
       "0  5.503767  0.266507  0.27307  ...      0.0                 0.0       0.0   \n",
       "1  0.000000  0.266507  0.27307  ...      0.0                 0.0       0.0   \n",
       "2  0.000000  0.000000  0.00000  ...      0.0                 0.0       0.0   \n",
       "3  0.000000  0.266507  0.27307  ...      0.0                 0.0       0.0   \n",
       "4  0.000000  0.266507  0.27307  ...      0.0                 0.0       0.0   \n",
       "\n",
       "   eurosave  self-inflicted  eurostat  upward  suicide-recording  scarcity  \\\n",
       "0       0.0             0.0       0.0     0.0                0.0       0.0   \n",
       "1       0.0             0.0       0.0     0.0                0.0       0.0   \n",
       "2       0.0             0.0       0.0     0.0                0.0       0.0   \n",
       "3       0.0             0.0       0.0     0.0                0.0       0.0   \n",
       "4       0.0             0.0       0.0     0.0                0.0       0.0   \n",
       "\n",
       "   trim-and-fill  \n",
       "0            0.0  \n",
       "1            0.0  \n",
       "2            0.0  \n",
       "3            0.0  \n",
       "4            0.0  \n",
       "\n",
       "[5 rows x 26951 columns]"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First we have to build TF-IDF matrix based on obtain dictionary. \n",
    "# Rows will correspond to docs in the corpus, while columns will represent unique words\n",
    "\n",
    "#              word1       ...          wordn\n",
    "#  doc1   tf_idf_value   ...      tf_idf_value\n",
    "#  ...    tf_idf_value   ...      tf_idf_value\n",
    "#  docn   tf_idf_value   ...      tf_idf_value\n",
    "#\n",
    "\n",
    "tf_idf_matrix = pd.DataFrame.from_dict(a, orient = 'index').fillna(0) # if word does not appear in doc we change NaN to\n",
    "tf_idf_matrix = tf_idf_matrix.sort_index()\n",
    "tf_idf_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alkylphenols         6.122806\n",
      "human                3.386148\n",
      "milk                 6.547579\n",
      "relations            5.429659\n",
      "dietary              2.097678\n",
      "                       ...   \n",
      "eurostat             0.000000\n",
      "upward               0.000000\n",
      "suicide-recording    0.000000\n",
      "scarcity             0.000000\n",
      "trim-and-fill        0.000000\n",
      "Name: 0, Length: 26951, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9999999999999997"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we have to compare docs by computing cosine similarity between each vector (row) in dataframe\n",
    "# For that we need to obtain 1. vector magintude 2. dot product between two vectors\n",
    "\n",
    "def vector_magnitude(v):\n",
    "    return np.linalg.norm(v)\n",
    "\n",
    "def dot_product(v1, v2):\n",
    "    return np.dot(v1,v2)\n",
    "\n",
    "# Creating cosine similarity table (should be 3193 x 3193)\n",
    "def cosine_similarity(v1, v2):\n",
    "    return dot_product(v1, v2)/ (vector_magnitude(v1) * vector_magnitude(v2))\n",
    "print(tf_idf_matrix.iloc[0])\n",
    "cosine_similarity(tf_idf_matrix.iloc[0],tf_idf_matrix.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preclustering suggested in the lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alkylphenols</th>\n",
       "      <th>human</th>\n",
       "      <th>milk</th>\n",
       "      <th>relations</th>\n",
       "      <th>dietary</th>\n",
       "      <th>habits</th>\n",
       "      <th>central</th>\n",
       "      <th>taiwan</th>\n",
       "      <th>pubmed</th>\n",
       "      <th>ncbi</th>\n",
       "      <th>...</th>\n",
       "      <th>tuscany</th>\n",
       "      <th>studies-depression</th>\n",
       "      <th>suicides</th>\n",
       "      <th>eurosave</th>\n",
       "      <th>self-inflicted</th>\n",
       "      <th>eurostat</th>\n",
       "      <th>upward</th>\n",
       "      <th>suicide-recording</th>\n",
       "      <th>scarcity</th>\n",
       "      <th>trim-and-fill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.613518</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.238922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266507</td>\n",
       "      <td>0.27307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266507</td>\n",
       "      <td>0.27307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266507</td>\n",
       "      <td>0.27307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.232891</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266507</td>\n",
       "      <td>0.27307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26951 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alkylphenols     human  milk  relations   dietary  habits  central  \\\n",
       "276           0.0  1.613518   0.0        0.0  1.238922     0.0      0.0   \n",
       "400           0.0  0.000000   0.0        0.0  0.000000     0.0      0.0   \n",
       "518           0.0  0.000000   0.0        0.0  0.000000     0.0      0.0   \n",
       "523           0.0  0.000000   0.0        0.0  0.000000     0.0      0.0   \n",
       "544           0.0  0.000000   0.0        0.0  3.232891     0.0      0.0   \n",
       "\n",
       "     taiwan    pubmed     ncbi  ...  tuscany  studies-depression  suicides  \\\n",
       "276     0.0  0.266507  0.27307  ...      0.0                 0.0       0.0   \n",
       "400     0.0  0.266507  0.27307  ...      0.0                 0.0       0.0   \n",
       "518     0.0  0.266507  0.27307  ...      0.0                 0.0       0.0   \n",
       "523     0.0  0.000000  0.00000  ...      0.0                 0.0       0.0   \n",
       "544     0.0  0.266507  0.27307  ...      0.0                 0.0       0.0   \n",
       "\n",
       "     eurosave  self-inflicted  eurostat  upward  suicide-recording  scarcity  \\\n",
       "276       0.0             0.0       0.0     0.0                0.0       0.0   \n",
       "400       0.0             0.0       0.0     0.0                0.0       0.0   \n",
       "518       0.0             0.0       0.0     0.0                0.0       0.0   \n",
       "523       0.0             0.0       0.0     0.0                0.0       0.0   \n",
       "544       0.0             0.0       0.0     0.0                0.0       0.0   \n",
       "\n",
       "     trim-and-fill  \n",
       "276            0.0  \n",
       "400            0.0  \n",
       "518            0.0  \n",
       "523            0.0  \n",
       "544            0.0  \n",
       "\n",
       "[5 rows x 26951 columns]"
      ]
     },
     "execution_count": 802,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set number of clusters at initialisation time\n",
    "sqrt_n = round(math.sqrt(no_of_docs))\n",
    "\n",
    "#we randomly select sqrt(N) documents from the corpus, which we call leaders\n",
    "leaders = tf_idf_matrix.sample(sqrt_n, random_state = 11)\n",
    "leaders = leaders.sort_index()\n",
    "leaders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For every other document in the collection\n",
    "# 1. Compute the similarities (cosine of the angle between TF-IDF vectors) with all leaders\n",
    "# 2. Add the document to the cluster of the most similar leader\n",
    "\n",
    "cluster_list = []\n",
    "\n",
    "for i in range(sqrt_n):\n",
    "    cluster_list.append([])\n",
    "\n",
    "for i in range(no_of_docs):\n",
    "    cosines = []\n",
    "    for j in leaders.index:\n",
    "        cosines.append(cosine_similarity(tf_idf_matrix.loc[i],leaders.loc[j]))\n",
    "    m = max(cosines)\n",
    "    index_of_max = [l for l, b in enumerate(cosines) if b == m]\n",
    "    cluster_list[index_of_max[0]].append(i) #if there are two equal max values of cosine similarity use the smaller index by default\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[48,\n",
       "  196,\n",
       "  197,\n",
       "  276,\n",
       "  278,\n",
       "  385,\n",
       "  419,\n",
       "  493,\n",
       "  495,\n",
       "  498,\n",
       "  540,\n",
       "  542,\n",
       "  568,\n",
       "  575,\n",
       "  585,\n",
       "  601,\n",
       "  662,\n",
       "  781,\n",
       "  784,\n",
       "  817,\n",
       "  893,\n",
       "  908,\n",
       "  1094,\n",
       "  1116,\n",
       "  1457,\n",
       "  1581,\n",
       "  1621,\n",
       "  1649,\n",
       "  1791,\n",
       "  1897,\n",
       "  1993,\n",
       "  2019,\n",
       "  2112,\n",
       "  2116,\n",
       "  2129,\n",
       "  2195,\n",
       "  2247,\n",
       "  2249,\n",
       "  2258,\n",
       "  2266,\n",
       "  2342,\n",
       "  2358,\n",
       "  2453,\n",
       "  2470,\n",
       "  2510,\n",
       "  2620,\n",
       "  2858,\n",
       "  2923,\n",
       "  2977,\n",
       "  3046]]"
      ]
     },
     "execution_count": 804,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_list[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all docs are distributed to the clusters\n"
     ]
    }
   ],
   "source": [
    "# check of total docs (every doc should be included in exactly one cluster)\n",
    "total = 0\n",
    "for i in range(len(cluster_list)):\n",
    "    total = total + len(cluster_list[i])\n",
    "\n",
    "if total == no_of_docs:\n",
    "    print('all docs are distributed to the clusters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct function, which uses query q(should be already in the vector form) as input, required similarity of the doc to be retrieved - threshold, and\n",
    "#necessary number of documents to be retrieved - K (5 most similar docs in the cluster by default)\n",
    "\n",
    "def ir_preclustering(q, threshold = 0, K = 5): \n",
    "    sim_to_leaders = [] #array of cosine similarities of q to leaders\n",
    "    retrieved_docs = [] #array of the most similar docs to be returned by the function\n",
    "    \n",
    "    for i in range(len(leaders.index)):\n",
    "        sim_to_leaders.append(cosine_similarity(q,leaders.iloc[i]))\n",
    "    m = max(sim_to_leaders)\n",
    "    index_of_max = [l for l, b in enumerate(sim_to_leaders) if b == m] #odinal number of most similar leader => use this cluster\n",
    "    \n",
    "    sim_to_docs = [] #array of cosine similarities of q to all docs in the chosen cluster\n",
    "    for doc in cluster_list[index_of_max[0]]:\n",
    "        sim_to_docs.append(cosine_similarity(q,tf_idf_matrix.iloc[doc]))\n",
    "        \n",
    "    ins = np.argsort(sim_to_docs) #returns the indices that would sort an array of similarities to docs in ascending order\n",
    "    ins = ins[::-1] #but we need descending (most similar in the beginning of the list)\n",
    "    \n",
    "    if threshold == 0: #proceed only with K\n",
    "        if len(ins)>=K:\n",
    "            for k in range(K):\n",
    "                retrieved_docs.append(cluster_list[index_of_max[0]][ins[k]])\n",
    "        else:\n",
    "            K=len(ins)\n",
    "            for k in range(K):\n",
    "                retrieved_docs.append(cluster_list[index_of_max[0]][ins[k]])\n",
    "\n",
    "        \n",
    "    else:\n",
    "        if sim_to_docs[ins[0]] < threshold:\n",
    "            print('no documents satisfy necessary level of threshold similarity')\n",
    "            return None\n",
    "        \n",
    "        for sim in sim_to_docs:\n",
    "            if sim >= threshold:\n",
    "                retrieved_docs.append(cluster_list[index_of_max[0]][sim_to_docs.index(sim)])\n",
    "            if len(retrieved_docs) < K:\n",
    "                print('number of documents that satisfy threshold similarity is less than required \\(less than K\\)')\n",
    "    \n",
    "    return corpus.iloc[retrieved_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# repeat this procedure using FAISS instead of cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float32"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FAISS works only with type float32\n",
    "print(type(tf_idf_matrix.loc[0][0]))\n",
    "tf_idf_matrix = tf_idf_matrix.astype('float32')\n",
    "print(type(tf_idf_matrix.loc[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are going to use the same leaders\n",
    "leaders = leaders.astype('float32')\n",
    "index = faiss.IndexFlatL2(len(leaders.columns))\n",
    "index.add(np.ascontiguousarray(leaders.values))\n",
    "\n",
    "#find the nearest leader\n",
    "def ir_preclustering_faiss(q, K = 5):\n",
    "    D, I = index.search(q, 1) #returning distance and index of the nearest leader\n",
    "    \n",
    "    index2 = faiss.IndexFlatL2(len(leaders.columns)) #train index of the cluster with nearest leader\n",
    "    index2.add(np.ascontiguousarray(cluster_list[I]))\n",
    "    \n",
    "    if len(cluster_list[I]) < K:\n",
    "        print('asked number of documents to be retrieved is larger than the number of documents in the cluster; \\nall documents in the cluster are retrieved')\n",
    "        return tf_idf_matrix.iloc[cluster_list[I]]\n",
    "    \n",
    "    else:\n",
    "        DD, II = index2.search(q, K) #returning distances and indexes of the nearest documents (sorted by distance)\n",
    "        return tf_idf_matrix.iloc[II]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "       n_clusters=57, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set number of clusters at initialisation time\n",
    "sqrt_n = round(math.sqrt(no_of_docs))\n",
    "\n",
    "#Run the clustering algorithm\n",
    "estimator = KMeans(n_clusters = sqrt_n)\n",
    "model = estimator.fit(tf_idf_matrix)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([33, 33, 13, ..., 16,  9,  9], dtype=int32)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generate cluster predictions and store in y_hat\n",
    "y_hat = estimator.predict(tf_idf_matrix) #predicting to which cluster the query belongs\n",
    "y_hat #array of belongings of docs to cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_list_kmeans = []\n",
    "for i in range(sqrt_n):\n",
    "    cluster_list_kmeans.append([])\n",
    "\n",
    "for i in range(no_of_docs):\n",
    "    for j in range(sqrt_n):\n",
    "        if y_hat[i] == j:\n",
    "            cluster_list_kmeans[j].append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2559], [164]]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_list_kmeans[0:2] #in one of the runs of kmeans not very balanced clusters: only one doc in cluster 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       ...,\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 2.71050543e-20,  4.22399631e-03,  8.67361738e-19, ...,\n",
       "        -3.38813179e-21, -1.69406589e-21,  0.00000000e+00]])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since we have 57 clusters, we are going to compare the query vector with 57 vectors of cluster centroids\n",
    "#All of cluster centroids are stored in the attribute cluster_centers\n",
    "centers = np.array(model.cluster_centers_)\n",
    "centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#construct function, which uses query q(should be already in the vector form) as input, required similarity of the doc to be retrieved - threshold, and\n",
    "#necessary number of documents to be retrieved - K (5 most similar docs in the cluster by default)\n",
    "\n",
    "def ir_preclustering_kmeans(q, threshold = 0, K = 5): \n",
    "    sim_to_centers = [] #array of cosine similarities of q to leaders\n",
    "    retrieved_docs = [] #array of the most similar docs to be returned by the function\n",
    "    \n",
    "    for i in leaders.index:\n",
    "        sim_to_centers.append(cosine_similarity(q,leaders.iloc[i]))\n",
    "    m = max(sim_to_centers)\n",
    "    index_of_max = [l for l, b in enumerate(sim_to_centers) if b == m] #odinal number of most similar leader => use this cluster\n",
    "    index_of_max = index_of_max[0]\n",
    "    \n",
    "    sim_to_docs = [] #array of cosine similarities of q to all docs in the chosen cluster\n",
    "    for doc in cluster_list[index_of_max]:\n",
    "        sim_to_docs.append(cosine_similarity(q,tf_idf_matrix.iloc[doc]))\n",
    "        \n",
    "    ins = np.argsort(sim_to_docs) #returns the indices that would sort an array of similarities to docs in accending order\n",
    "    \n",
    "    if threshold == 0: #proceed only with K\n",
    "        for k in range(K):\n",
    "            retrieved_docs.append(cluster_list_kmeans[m][-k-1])\n",
    "\n",
    "        df_retrieved_docs = tf_idf_matrix.iloc[retrieved_docs] #construct the dataframe of retrieved docs to be returned by the function\n",
    "    \n",
    "    else:\n",
    "        if sim_to_docs[ins[0]] < threshold:\n",
    "            print('no documents satisfy necessary level of threshold similarity')\n",
    "            return None\n",
    "        \n",
    "        for sim in sim_to_docs:\n",
    "            if sim >= threshold:\n",
    "                retrieved_docs.append(cluster_list_kmeans[m][sim_to_docs.index(sim)])\n",
    "            if len(retrieved_docs) < K:\n",
    "                print('number of documents that satisfy threshold similarity is less than required \\(less than K\\)')\n",
    "            df_retrieved_docs = tf_idf_matrix.iloc[retrieved_docs]\n",
    "        \n",
    "    return df_retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QUERY_ID</th>\n",
       "      <th>0</th>\n",
       "      <th>DOC_ID</th>\n",
       "      <th>RELEVANCE_LEVEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-2421</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-2422</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-2416</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-2423</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-2417</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-2418</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-4451</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-2420</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-2414</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>0</td>\n",
       "      <td>MED-4070</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  QUERY_ID  0    DOC_ID  RELEVANCE_LEVEL\n",
       "0  PLAIN-1  0  MED-2421                2\n",
       "1  PLAIN-1  0  MED-2422                2\n",
       "2  PLAIN-1  0  MED-2416                2\n",
       "3  PLAIN-1  0  MED-2423                2\n",
       "4  PLAIN-1  0  MED-2417                2\n",
       "5  PLAIN-1  0  MED-2418                2\n",
       "6  PLAIN-1  0  MED-4451                2\n",
       "7  PLAIN-1  0  MED-2420                2\n",
       "8  PLAIN-1  0  MED-2414                1\n",
       "9  PLAIN-1  0  MED-4070                1"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_relevance = pd.read_csv('nfcorpus/dev.2-1-0.qrel', sep='\\t', names=['QUERY_ID', '0', 'DOC_ID', 'RELEVANCE_LEVEL'])\n",
    "queries_relevance.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PLAIN-1</td>\n",
       "      <td>why deep fried foods may cause cancer in the l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PLAIN-1007</td>\n",
       "      <td>ddt - - persistent organic pollutants , indust...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PLAIN-101</td>\n",
       "      <td>how to treat multiple sclerosis with diet mult...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PLAIN-1017</td>\n",
       "      <td>detoxification - - cancer , raw food , heart h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PLAIN-1027</td>\n",
       "      <td>dietary guidelines - - heart disease , cardiov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PLAIN-1038</td>\n",
       "      <td>dogs - - meat , animal products , cats , heart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PLAIN-1049</td>\n",
       "      <td>dr. david spence - - heart health , heart dise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PLAIN-1065</td>\n",
       "      <td>dr. walter kempner - - mortality , heart disea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PLAIN-1077</td>\n",
       "      <td>dulse - - thyroid health , hijiki , sushi , io...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PLAIN-1087</td>\n",
       "      <td>easter island - - mortality , muscle strength ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                                               TEXT\n",
       "0     PLAIN-1  why deep fried foods may cause cancer in the l...\n",
       "1  PLAIN-1007  ddt - - persistent organic pollutants , indust...\n",
       "2   PLAIN-101  how to treat multiple sclerosis with diet mult...\n",
       "3  PLAIN-1017  detoxification - - cancer , raw food , heart h...\n",
       "4  PLAIN-1027  dietary guidelines - - heart disease , cardiov...\n",
       "5  PLAIN-1038  dogs - - meat , animal products , cats , heart...\n",
       "6  PLAIN-1049  dr. david spence - - heart health , heart dise...\n",
       "7  PLAIN-1065  dr. walter kempner - - mortality , heart disea...\n",
       "8  PLAIN-1077  dulse - - thyroid health , hijiki , sushi , io...\n",
       "9  PLAIN-1087  easter island - - mortality , muscle strength ..."
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_text = pd.read_csv('nfcorpus/dev.all.queries', sep='\\t', names=['ID', 'TEXT'])\n",
    "queries_text.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alkylphenols</th>\n",
       "      <th>human</th>\n",
       "      <th>milk</th>\n",
       "      <th>relations</th>\n",
       "      <th>dietary</th>\n",
       "      <th>habits</th>\n",
       "      <th>central</th>\n",
       "      <th>taiwan</th>\n",
       "      <th>pubmed</th>\n",
       "      <th>ncbi</th>\n",
       "      <th>...</th>\n",
       "      <th>tuscany</th>\n",
       "      <th>studies-depression</th>\n",
       "      <th>suicides</th>\n",
       "      <th>eurosave</th>\n",
       "      <th>self-inflicted</th>\n",
       "      <th>eurostat</th>\n",
       "      <th>upward</th>\n",
       "      <th>suicide-recording</th>\n",
       "      <th>scarcity</th>\n",
       "      <th>trim-and-fill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 26951 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [alkylphenols, human, milk, relations, dietary, habits, central, taiwan, pubmed, ncbi, abstract, aims, study, determine, concentrations, num, nonylphenol, np, octylphenol, op, samples, examine, related, factors, including, mothers, demographics, women, consumed, median, amount, cooking, oil, significantly, higher, ng/g, concentration, consumption, beta, fish, capsules, adjustment, age, body, mass, index, bmi, processed, products, food, pattern, meat, factor, analysis, strongly, determinations, aid, suggesting, foods, nursing, order, protect, infants, np/op, exposure, elsevier, rights, reserved, phosphate, vascular, toxin, elevated, levels, advanced, renal, failure, dysregulated, calcium, parathyroid, hormone, vitamin, contribute, complex, chronic, kidney, disease-mineral, bone, disease, ckd-mbd, converging, evidence, vitro, clinical, epidemiological, studies, suggest, increased, calcification, mortality, vessels, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 26951 columns]"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_queries = tf_idf_matrix[0:0]\n",
    "tf_idf_queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3): #range(len(queries_text)):\n",
    "    tf_idf_queries = tf_idf_queries.append(pd.Series(0, index=tf_idf_queries.columns), ignore_index=True)\n",
    "    tokenized_query = queries_text['TEXT'][0].split()\n",
    "    for token in tokenized_query:\n",
    "        for col in tf_idf_queries.columns:\n",
    "            if token == col:\n",
    "                tf_idf_queries[col][i] = tf_idf_queries[col][i] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alkylphenols</th>\n",
       "      <th>human</th>\n",
       "      <th>milk</th>\n",
       "      <th>relations</th>\n",
       "      <th>dietary</th>\n",
       "      <th>habits</th>\n",
       "      <th>central</th>\n",
       "      <th>taiwan</th>\n",
       "      <th>pubmed</th>\n",
       "      <th>ncbi</th>\n",
       "      <th>...</th>\n",
       "      <th>tuscany</th>\n",
       "      <th>studies-depression</th>\n",
       "      <th>suicides</th>\n",
       "      <th>eurosave</th>\n",
       "      <th>self-inflicted</th>\n",
       "      <th>eurostat</th>\n",
       "      <th>upward</th>\n",
       "      <th>suicide-recording</th>\n",
       "      <th>scarcity</th>\n",
       "      <th>trim-and-fill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 26951 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   alkylphenols  human  milk  relations  dietary  habits  central  taiwan  \\\n",
       "0           0.0    1.0   0.0        0.0     11.0     0.0      0.0     0.0   \n",
       "1           0.0    1.0   0.0        0.0     11.0     0.0      0.0     0.0   \n",
       "2           0.0    1.0   0.0        0.0     11.0     0.0      0.0     0.0   \n",
       "\n",
       "   pubmed  ncbi  ...  tuscany  studies-depression  suicides  eurosave  \\\n",
       "0     2.0   0.0  ...      0.0                 0.0       0.0       0.0   \n",
       "1     2.0   0.0  ...      0.0                 0.0       0.0       0.0   \n",
       "2     2.0   0.0  ...      0.0                 0.0       0.0       0.0   \n",
       "\n",
       "   self-inflicted  eurostat  upward  suicide-recording  scarcity  \\\n",
       "0             0.0       0.0     0.0                0.0       0.0   \n",
       "1             0.0       0.0     0.0                0.0       0.0   \n",
       "2             0.0       0.0     0.0                0.0       0.0   \n",
       "\n",
       "   trim-and-fill  \n",
       "0            0.0  \n",
       "1            0.0  \n",
       "2            0.0  \n",
       "\n",
       "[3 rows x 26951 columns]"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_query(string):\n",
    "    tokenized_query = string.split()\n",
    "    df_query = tf_idf_matrix[0:0] #dataframe of tf-idf weights of a query\n",
    "    df_query = df_query.append(pd.Series(0, index=df_query.columns), ignore_index=True)\n",
    "    for token in tokenized_query:\n",
    "        for col in df_query.columns:\n",
    "            if token == col:\n",
    "                df_query[col][0] = df_query[col][0] + 1 #raw term frequency\n",
    "    \n",
    "    df_query = df_query.replace(0, np.nan)\n",
    "    \n",
    "    df_query = np.log(df_query) + 1 #log term freq(as in the slides)\n",
    "    \n",
    "    df_query = df_query.fillna(0)\n",
    "    \n",
    "    for col in df_query.columns:\n",
    "        df_query[col][0] = df_query[col][0] * idf[col]\n",
    "        \n",
    "    return df_query\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_with_preclustering(string_query, k = 5, IDs_of_retrieved_docs = False):\n",
    "    print(\"\")\n",
    "    vector_q = vectorize_query(string_query)\n",
    "    return ir_preclustering(vector_q.iloc[0], K = k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>MED-2423</td>\n",
       "      <td>dietary patterns breast cancer risk women pubm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>MED-2418</td>\n",
       "      <td>consumption deep-fried foods risk prostate can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>MED-2195</td>\n",
       "      <td>influence deep frying vegetable oils acrylamid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>MED-3498</td>\n",
       "      <td>dietary acrylamide exposure french population ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3004</th>\n",
       "      <td>MED-5088</td>\n",
       "      <td>mitigation strategies reduce acrylamide format...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>MED-2416</td>\n",
       "      <td>chronic intake potato chips humans increases p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3011</th>\n",
       "      <td>MED-5095</td>\n",
       "      <td>bioequivalence docosahexaenoic acid algal oils...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3001</th>\n",
       "      <td>MED-5085</td>\n",
       "      <td>factors dominating adhesion nacl potato chips ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>MED-2420</td>\n",
       "      <td>acrylamide foods review science future conside...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>MED-2191</td>\n",
       "      <td>effects baking boiling nutritional antioxidant...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                                               TEXT\n",
       "1142  MED-2423  dietary patterns breast cancer risk women pubm...\n",
       "1138  MED-2418  consumption deep-fried foods risk prostate can...\n",
       "956   MED-2195  influence deep frying vegetable oils acrylamid...\n",
       "1794  MED-3498  dietary acrylamide exposure french population ...\n",
       "3004  MED-5088  mitigation strategies reduce acrylamide format...\n",
       "1136  MED-2416  chronic intake potato chips humans increases p...\n",
       "3011  MED-5095  bioequivalence docosahexaenoic acid algal oils...\n",
       "3001  MED-5085  factors dominating adhesion nacl potato chips ...\n",
       "1139  MED-2420  acrylamide foods review science future conside...\n",
       "954   MED-2191  effects baking boiling nutritional antioxidant..."
      ]
     },
     "execution_count": 600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_with_preclustering(queries_text['TEXT'][0], k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find all relevant documents for the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_relevant_docs(string_query):\n",
    "    query_row = (queries_text.loc[queries_text['TEXT'].isin([string_query])])\n",
    "    query_id = query_row.iloc[0][\"ID\"]\n",
    "    relevance_lvl = [1, 2]\n",
    "    return queries_relevance.loc[queries_relevance['QUERY_ID'].isin([query_id]) & queries_relevance['RELEVANCE_LEVEL'].isin(relevance_lvl)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate performance by:\n",
    " Precision\n",
    " MAP \n",
    " nDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(actual, predicted):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), len(predicted))\n",
    "\n",
    "def mapk(actual, predicted, k=5):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k.\n",
    "    This function computes the mean average prescision at k between two lists\n",
    "    of lists of items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of lists of elements that are to be predicted \n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg(element_list):\n",
    "    \"\"\"\n",
    "    Discounted Cumulative Gain (DCG)\n",
    "    Parameters:\n",
    "        element_list - a list of ranks Ex: [5,4,2,2,1]\n",
    "    Returns:\n",
    "        score\n",
    "    \"\"\"\n",
    "    score = 0.0\n",
    "    for order, rank in enumerate(element_list):\n",
    "        score += float(rank)/math.log((order+2))\n",
    "    return score\n",
    "\n",
    "\n",
    "def ndcg(reference, hypothesis):\n",
    "    \"\"\"\n",
    "    Normalized Discounted Cumulative Gain (nDCG)\n",
    "    Normalized version of DCG:\n",
    "        nDCG = DCG(hypothesis)/DCG(reference)\n",
    "    Parameters:\n",
    "        reference   - a gold standard (perfect) ordering Ex: [5,4,3,2,1]\n",
    "        hypothesis  - a proposed ordering Ex: [5,2,2,3,1]\n",
    "    Returns:\n",
    "        ndcg_score  - normalized score\n",
    "    \"\"\"\n",
    "    if dcg(reference) == 0:\n",
    "        return 0 \n",
    "    else:\n",
    "        return dcg(hypothesis)/dcg(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_retrieve_with_preclustering(query_text):\n",
    "    ## returns the triple (Precision, Average Precision, Normalized Discounted Cumulative Gain)\n",
    "    \n",
    "    retrieved_df = retrieve_with_preclustering(query_text)\n",
    "    ids_retrieved = []\n",
    "    for i in range(len(retrieved_df)):\n",
    "        ids_retrieved.append(retrieved_df.iloc[i].ID)\n",
    "    ids_retrieved.sort()\n",
    "    \n",
    "    relevant = true_relevant_docs(query_text)\n",
    "    ids_true_relevant = []\n",
    "    for i in range(len(relevant)):\n",
    "        ids_true_relevant.append(relevant.iloc[i].DOC_ID)\n",
    "    ids_true_relevant.sort()\n",
    "    \n",
    "    #count true positives and false positives\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    for i in ids_retrieved:\n",
    "        for j in ids_true_relevant:\n",
    "            if i == j:\n",
    "                tp += 1 \n",
    "                break\n",
    "            else:\n",
    "                if i < j:\n",
    "                    fp += 1 \n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "    if (tp == 0) & (fp == 0):\n",
    "        precision = 0\n",
    "    else:\n",
    "        precision = tp/(tp+fp)\n",
    "    #cannot calculate recall, since we predefined the number of retrieved documents => apriori algorithm cannot retrieve all documents\n",
    "    \n",
    "    #then calculate Average precision across retrieved documents\n",
    "    ap = apk(ids_true_relevant, ids_retrieved)\n",
    "    \n",
    "    #since we have graded relevance annotations, we can also calculate Normalized Discounted Cumulative Gain\n",
    "    list_of_ranks_of_retrieved_docs = []\n",
    "    for i in ids_retrieved:\n",
    "        if i in ids_true_relevant:\n",
    "            list_of_ranks_of_retrieved_docs.append(relevant.loc[relevant['DOC_ID'].isin([i])].RELEVANCE_LEVEL.iloc[0])\n",
    "        else:\n",
    "            list_of_ranks_of_retrieved_docs.append(0)\n",
    "\n",
    "                                               \n",
    "    list_of_ranks_of_relevant_docs = []\n",
    "    for i in ids_true_relevant:\n",
    "        list_of_ranks_of_relevant_docs.append(relevant.loc[relevant['DOC_ID'].isin([i])].RELEVANCE_LEVEL.iloc[0])\n",
    "    list_of_ranks_of_relevant_docs.sort(reverse = True)\n",
    "    \n",
    "    k=len(list_of_ranks_of_retrieved_docs)\n",
    "    list_of_ranks_of_relevant_docs = list_of_ranks_of_relevant_docs[:k]\n",
    "        \n",
    "    return precision, ap, ndcg(list_of_ranks_of_relevant_docs, list_of_ranks_of_retrieved_docs)       \n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_preclustering():\n",
    "    evaluation = queries_text.copy()\n",
    "    evaluation.insert(2, \"Precision\", 0)\n",
    "    evaluation.insert(3, \"Average Precision\", 0)\n",
    "    evaluation.insert(4, \"nDCG\", 0)\n",
    "    \n",
    "    for i in range(len(evaluation)):\n",
    "\n",
    "        p, a, n = evaluate_retrieve_with_preclustering(queries_text.loc[i, 'TEXT'])\n",
    "        evaluation.loc[i, 'Precision'] = p\n",
    "        evaluation.loc[i, 'Average Precision'] = a\n",
    "        evaluation.loc[i, 'nDCG'] = n\n",
    "    \n",
    "    print('Average precision across all queries = ' + str(evaluation['Precision'].mean()))\n",
    "    print('Mean Average Precision = ' + str(evaluation['Average Precision'].mean()))\n",
    "    print('Average nDCG = ' + str(evaluation['nDCG'].mean()))\n",
    "    \n",
    "    return evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_with_leaders_state_11 = evaluate_preclustering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_with_leaders_state_11.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
